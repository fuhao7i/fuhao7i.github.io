I"<blockquote>
  <p>最近接到师姐任务，让用mmdetection工具箱完成一个目标检测模块。但是这个工具箱版本更新实在太快，而且各个版本，pytorch gpu的版本还不相同。搭建GPU环境实在繁琐，而且稍不注意程序就会报各种各样的错误。既然可以有各种工具箱用于目标检测，语义分割等任务，那为什么不可以有一个工具箱来帮助大家管理和配置python环境呢？这也是我创建Dali工具箱的初衷。</p>
</blockquote>

<h1 id="1-anaconda安装">1. Anaconda安装</h1>

<p>Anaconda是一个管理Python环境特别好的工具箱。它可以很方便的让你在电脑上管理多个Python环境，具体可以参考Anaconda官网或者其他博客。</p>

<h1 id="2-安装cuda">2. 安装CUDA</h1>

<blockquote>
  <p>要想利用GPU进行运算，除了在电脑上安装GPU的驱动外，我们还需要安装对应版本的CUDA(Compute Unified Device Architecture)，这是显卡厂商NVIDIA推出的运算平台。CUDA™是一种由NVIDIA推出的通用并行计算架构，该架构使GPU能够解决复杂的计算问题。</p>
</blockquote>

<p>我们要安装GPU版本的torch就需要使用CUDA。</p>

<h2 id="21-查看电脑上现有的cuda版本">2.1 查看电脑上现有的CUDA版本</h2>

<pre><code class="language-Bash">cat /usr/local/cuda/version.txt 
</code></pre>

<h2 id="22-确认gpu所支持的cuda版本">2.2 <a href="https://developer.nvidia.com/zh-cn/cuda-gpus">确认GPU所支持的CUDA版本</a></h2>

<h1 id="3-安装cudaa">3. 安装cuDAA</h1>

<blockquote>
  <p>NVIDIA cuDNN是用于深度神经网络的GPU加速库。它强调性能、易用性和低内存开销。NVIDIA cuDNN可以集成到更高级别的机器学习框架中，如谷歌的Tensorflow、加州大学伯克利分校的流行caffe软件。简单的插入式设计可以让开发人员专注于设计和实现神经网络模型，而不是简单调整性能，同时还可以在GPU上实现高性能现代并行计算。</p>
</blockquote>

<h2 id="31-查看和你cuda版本对应的cudnn版本并下载"><a href="https://developer.nvidia.com/rdp/cudnn-archive">3.1 查看和你CUDA版本对应的cuDNN版本，并下载</a></h2>

<h1 id="4-cuda和cudnn的关系">4. CUDA和cuDNN的关系</h1>

<p><strong>CUDA是底层架构，类似于一个工具箱。cuDNN是基于CUDA的深度学习GPU加速库，有了它才能在GPU上完成深度学习的计算，它就相当于是实现具体功能的一个具体的工具，比如说扳手🔧。但是我们安装CUDA的时候，并没有赠送这个扳手，我们需要把cuDNN下载下来，放入工具箱中(即插入式设计，<code class="language-plaintext highlighter-rouge">cuDNN不会对CUDA产生任何影响</code>，因为是把cuDNN的文件复制到CUDA文件夹里，并没有相同文件覆盖的问题)。所以安装cuDNN也就是放文件和删除文件的问题。</strong></p>
:ET