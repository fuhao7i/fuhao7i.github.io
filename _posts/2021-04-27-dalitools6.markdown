---
layout:     post
title:      "Dali工具箱🕶6——Compute Confusion Matrix"
subtitle:   " \"confusion matrix, TP, FP, TN, FN, Precision, IoU, Recall \""
date:       2021-04-27 14:06:00
author:     "fuhao7i"
header-img: "img/in-post/tools.jpg"
catalog: true
tags:
    - Dali工具箱🕶
---

<img src="https://img-blog.csdnimg.cn/20210427225249883.png#pic_center">

# 1.sklearn.metrics.confusion_matrix (y_true, y_pred, labels=None, sample_weight=None)

y_true为真实值, y_pred为预测值(softmax之后, 取最大值的坐标, 即预测的像素点类别)  `y_true和y_pred都需要flatten为一维数组`

```python
>>> from sklearn.metrics import confusion_matrix
>>> y_true = [2, 0, 2, 2, 0, 1]
>>> y_pred = [0, 0, 2, 2, 0, 2]
>>> confusion_matrix(y_true, y_pred)
```
```Bash
array([[2, 0, 0],
       [0, 0, 1],
       [1, 0, 2]])
```

或

```python
>>> y_true = ["cat", "ant", "cat", "cat", "ant", "bird"]
>>> y_pred = ["ant", "ant", "cat", "cat", "ant", "cat"]
>>> confusion_matrix(y_true, y_pred, labels=["ant", "bird", "cat"])
```
```Bash
array([[2, 0, 0],
       [0, 0, 1],
       [1, 0, 2]])
```

# 2.Implement by Torch

```python
def compute_results(conf_total):
    n_class =  conf_total.shape[0]
    consider_unlabeled = True  # must consider the unlabeled, please set it to True
    if consider_unlabeled is True:
        start_index = 0
    else:
        start_index = 1
    precision_per_class = np.zeros(n_class)
    recall_per_class = np.zeros(n_class)
    iou_per_class = np.zeros(n_class)
    for cid in range(start_index, n_class): # cid: class id
        if conf_total[start_index:, cid].sum() == 0:
            precision_per_class[cid] =  np.nan
        else:
            precision_per_class[cid] = float(conf_total[cid, cid]) / float(conf_total[start_index:, cid].sum()) # precision = TP/TP+FP
        if conf_total[cid, start_index:].sum() == 0:
            recall_per_class[cid] = np.nan
        else:
            recall_per_class[cid] = float(conf_total[cid, cid]) / float(conf_total[cid, start_index:].sum()) # recall = TP/TP+FN
        if (conf_total[cid, start_index:].sum() + conf_total[start_index:, cid].sum() - conf_total[cid, cid]) == 0:
            iou_per_class[cid] = np.nan
        else:
            iou_per_class[cid] = float(conf_total[cid, cid]) / float((conf_total[cid, start_index:].sum() + conf_total[start_index:, cid].sum() - conf_total[cid, cid])) # IoU = TP/TP+FP+FN

    return precision_per_class, recall_per_class, iou_per_class




def val(model, dataloader, optimizer, logger, epoch, Epoches, work_dir, NUM_CLASSES):
    model = model.eval()
    conf_total = np.zeros((NUM_CLASSES, NUM_CLASSES))

    for iter, batch in enumerate(dataloader):

        imgs, pngs, labels = batch

        imgs = Variable(torch.from_numpy(imgs).type(torch.FloatTensor))
        pngs = Variable(torch.from_numpy(pngs).type(torch.FloatTensor)).long()
        labels = Variable(torch.from_numpy(labels).type(torch.FloatTensor))

        imgs = imgs.cuda()
        pngs = pngs.cuda()
        labels = labels.cuda() 

        outputs = model(imgs)
        loss = F.cross_entropy(outputs, pngs)
        #loss = CE_Loss(outputs, pngs, num_classes = NUM_CLASSES)
        
        label = pngs.cpu().numpy().squeeze().flatten()
        prediction = outputs.argmax(1).cpu().numpy().squeeze().flatten()
        conf = confusion_matrix(y_true=label, y_pred=prediction, labels=[0,1,2,3,4])
        conf_total += conf

    precision, recall, IoU = compute_results(conf_total)
```

