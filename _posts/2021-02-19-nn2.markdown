---
layout:     post
title:      "Neural NetworkğŸ¦–2â€”â€”ä¼˜åŒ–å™¨è¯¦è§£"
subtitle:   " \"ä¼˜åŒ–å™¨çš„ä½œç”¨ä¸å®ç°åŸç†\""
date:       2021-02-20 14:17:00
author:     "fuhao7i"
header-img: "img/in-post/nn.jpg"
catalog: true
tags:
    - Neural NetworkğŸ¦–
---

# 2. lr_scheduler å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥

### 2.1 ReduceLROnPlateau

ç›®å‰ä¸ä¾èµ–epochæ›´æ–°lrçš„åªæœ‰`torch.optim.lr_scheduler.ReduceLROnPlateau`.

### 2.2 StepLR

**grammar**

```python
class torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1)
```

**update strategy**

æ¯è¿‡ä¸€ä¸ª`step_size`ä¸ªepochï¼Œåšä¸€æ¬¡æ›´æ–°:

$$
\large new\_lr = initial\_lr * gamma^{epoch//step\_size} \tag 1
$$

**parameters**

1. optimizer: è¦æ›´æ”¹çš„ä¼˜åŒ–å™¨
2. step_size: æ¯è®­ç»ƒstep_sizeä¸ªepochï¼Œæ›´æ–°ä¸€æ¬¡æƒé‡
3. gamma: æ›´æ–°lrçš„ä¹˜æ³•å› å­
4. last_epoch: æœ€åä¸€ä¸ªepochçš„indexï¼Œå¦‚æœæ˜¯è®­ç»ƒäº†å¾ˆå¤šä¸ªepochåä¸­æ–­äº†ï¼Œç»§ç»­è®­ç»ƒï¼Œè¿™ä¸ªå€¼å°±ç­‰äºåŠ è½½çš„æ¨¡å‹çš„epochã€‚é»˜è®¤ä¸º-1è¡¨ç¤ºä»å¤´å¼€å§‹è®­ç»ƒï¼Œå³ä»epoch=1å¼€å§‹

`e.g`

```python
import torch
import torch.nn as nn
from torch.optim.lr_scheduler import StepLR
import itertools


initial_lr = 0.1

class model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3)

    def forward(self, x):
        pass

net_1 = model()

optimizer_1 = torch.optim.Adam(net_1.parameters(), lr = initial_lr)
scheduler_1 = StepLR(optimizer_1, step_size=3, gamma=0.1)

print("åˆå§‹åŒ–çš„å­¦ä¹ ç‡ï¼š", optimizer_1.defaults['lr'])

for epoch in range(1, 11):
    # train

    optimizer_1.zero_grad()
    optimizer_1.step()
    print("ç¬¬%dä¸ªepochçš„å­¦ä¹ ç‡ï¼š%f" % (epoch, optimizer_1.param_groups[0]['lr']))
    scheduler_1.step()
```

### 1. ä¼ å…¥ä¸¤ä¸ªæ¨¡å‹å‚æ•°
`å­—å…¸å½¢å¼`
```python
optimizer = torch.optim.SGD([
                {'params': model.parameters()},
                {'params': lossnet.parameters(), 'lr': 1e-4}
            ], lr, momentum=0.9)
```
# å¼•ç”¨:
1. [pytorchä¼˜åŒ–å™¨ä¼ å…¥ä¸¤ä¸ªæ¨¡å‹çš„å‚æ•°/å·²ä¸åŒçš„å­¦ä¹ é€Ÿç‡è®­ç»ƒæ¨¡å‹](https://blog.csdn.net/u011622208/article/details/90698688)