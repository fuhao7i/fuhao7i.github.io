<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>fuhao7i Blog</title>
    <description>è¿™é‡Œæ˜¯ @fuhao7i çš„ä¸ªäººåšå®¢ï¼Œæˆ‘è¿˜å¾ˆå¹´è½»ï¼Œåƒè‹¦è¶ç°åœ¨ï¼</description>
    <link>https://fuhao7i.github.io/</link>
    <atom:link href="https://fuhao7i.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 13 Apr 2021 21:20:59 +0800</pubDate>
    <lastBuildDate>Tue, 13 Apr 2021 21:20:59 +0800</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>Daliæ‚è´§é“ºğŸ°20â€”â€”Common operations of tensors</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;record the common operations of tensors.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;1-torchcattensor1-tensor2-dim&quot;&gt;1. torch.cat((tensor1, tensor2), dim)&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;cat is â€˜concatenateâ€™, menas link (things) together in a chain or series.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&quot;language-Bash&quot;&gt;&amp;gt;&amp;gt;&amp;gt; import torch
&amp;gt;&amp;gt;&amp;gt; A=torch.ones(2,3) #2x3çš„å¼ é‡ï¼ˆçŸ©é˜µï¼‰                                     
&amp;gt;&amp;gt;&amp;gt; A
tensor([[ 1.,  1.,  1.],
        [ 1.,  1.,  1.]])
&amp;gt;&amp;gt;&amp;gt; B=2*torch.ones(4,3)#4x3çš„å¼ é‡ï¼ˆçŸ©é˜µï¼‰                                    
&amp;gt;&amp;gt;&amp;gt; B
tensor([[ 2.,  2.,  2.],
        [ 2.,  2.,  2.],
        [ 2.,  2.,  2.],
        [ 2.,  2.,  2.]])
&amp;gt;&amp;gt;&amp;gt; C=torch.cat((A,B),0)#æŒ‰ç»´æ•°0ï¼ˆè¡Œï¼‰æ‹¼æ¥
&amp;gt;&amp;gt;&amp;gt; C
tensor([[ 1.,  1.,  1.],
         [ 1.,  1.,  1.],
         [ 2.,  2.,  2.],
         [ 2.,  2.,  2.],
         [ 2.,  2.,  2.],
         [ 2.,  2.,  2.]])
&amp;gt;&amp;gt;&amp;gt; C.size()
torch.Size([6, 3])
&amp;gt;&amp;gt;&amp;gt; D=2*torch.ones(2,4) #2x4çš„å¼ é‡ï¼ˆçŸ©é˜µï¼‰
&amp;gt;&amp;gt;&amp;gt; C=torch.cat((A,D),1)#æŒ‰ç»´æ•°1ï¼ˆåˆ—ï¼‰æ‹¼æ¥
&amp;gt;&amp;gt;&amp;gt; C
tensor([[ 1.,  1.,  1.,  2.,  2.,  2.,  2.],
        [ 1.,  1.,  1.,  2.,  2.,  2.,  2.]])
&amp;gt;&amp;gt;&amp;gt; C.size()
torch.Size([2, 7])
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Wed, 14 Apr 2021 05:07:00 +0800</pubDate>
        <link>https://fuhao7i.github.io/2021/04/14/sundry20/</link>
        <guid isPermaLink="true">https://fuhao7i.github.io/2021/04/14/sundry20/</guid>
        
        <category>Daliæ‚è´§é“ºğŸ°</category>
        
        
      </item>
    
      <item>
        <title>DetectorğŸ¯5â€”â€” one-stage VS two-stage</title>
        <description>&lt;h1 id=&quot;1-main-differences&quot;&gt;1. main differences&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;one-stage network is faster.&lt;/li&gt;
  &lt;li&gt;two-stage network is more accurate.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;2-one-stage&quot;&gt;2. one-stage&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Directly regress the category probability and position coordinate value of the object without RPN(region proposal network).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;classical one-stage object detection network&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-Bash&quot;&gt;YOLOv1, YOLOv2, YOLOv3
SSD, DSSD ...
Retina-Net ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;retina-net&quot;&gt;&lt;a href=&quot;https://blog.csdn.net/cp1314971/article/details/105841094/&quot;&gt;Retina Net&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20210413164117265.png&quot; center=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://github.com/kuangliu/pytorch-retinanet&quot;&gt;PyTorch-RetinaNet&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 14 Apr 2021 02:50:00 +0800</pubDate>
        <link>https://fuhao7i.github.io/2021/04/14/detector5/</link>
        <guid isPermaLink="true">https://fuhao7i.github.io/2021/04/14/detector5/</guid>
        
        <category>DetectorğŸ¯</category>
        
        
      </item>
    
      <item>
        <title>Neural NetworkğŸ¦–8â€”â€”model.eval() VS with torch.no_grad()</title>
        <description>&lt;p&gt;&lt;strong&gt;In short&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;model.eval()&lt;/strong&gt; will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;torch.no_grad()&lt;/strong&gt; impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you wonâ€™t be able to backprop(which you donâ€™t want in an eval script).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_loader&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_batch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;reference&quot;&gt;reference&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615&quot;&gt;â€˜model.eval()â€™ vs â€˜with torch.no_grad()â€™&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 13 Apr 2021 18:12:00 +0800</pubDate>
        <link>https://fuhao7i.github.io/2021/04/13/nn8/</link>
        <guid isPermaLink="true">https://fuhao7i.github.io/2021/04/13/nn8/</guid>
        
        <category>Neural NetworkğŸ¦–</category>
        
        
      </item>
    
      <item>
        <title>Daliæ‚è´§é“ºğŸ°19â€”â€”Rules for defining the names of hyperparameters in torch</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;Sometimes, we need to train models jointly, or use one model to help another model training. So itâ€™s critically for us to konw the name of parameters in the model.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;monet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;monet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pre_conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;48&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;48&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;48&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;48&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ModuleList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arch_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;autograd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pre_conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arch_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;monet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arch_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pre_conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;outputs:&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-Bash&quot;&gt;pre_conv.0.weight
pre_conv.0.bias
conv0.weight
conv0.bias
layers.0.weight
layers.0.bias
layers.1.weight
layers.1.bias
layers.2.weight
layers.2.bias
[tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True), tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)]
Sequential(
  (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (1): ReLU(inplace=True)
)
&amp;lt;generator object Module.parameters at 0x7f22dfa5bb50&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Sat, 10 Apr 2021 23:46:00 +0800</pubDate>
        <link>https://fuhao7i.github.io/2021/04/10/sundry19/</link>
        <guid isPermaLink="true">https://fuhao7i.github.io/2021/04/10/sundry19/</guid>
        
        <category>Daliæ‚è´§é“ºğŸ°</category>
        
        
      </item>
    
      <item>
        <title>Neural NetworkğŸ¦–7â€”â€”How to clip gradient?</title>
        <description>&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;Due to the improper selection of the learning rate, the weight update is larger.&lt;/li&gt;
    &lt;li&gt;There is a lot of noise in the prepared data, resulting in large differences in target variables.&lt;/li&gt;
    &lt;li&gt;The improper selection of the loss function results in the calculation of a larger error value.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±çš„ä¸€ç§å¸¸è§è§£å†³æ–¹æ³•æ˜¯é‡æ–°ç¼©æ”¾è¯¯å·®å¯¼æ•°ï¼Œé€šè¿‡ç½‘ç»œåå‘ä¼ æ’­è¯¯å·®å¯¼æ•°ï¼Œç„¶åä½¿ç”¨å®ƒæ¥æ›´æ–°æƒé‡ã€‚é€šè¿‡é‡æ–°ç¼©æ”¾è¯¯å·®å¯¼æ•°ï¼Œæƒé‡çš„æ›´æ–°ä¹Ÿå°†è¢«é‡æ–°ç¼©æ”¾ï¼Œä»è€Œå¤§å¤§é™ä½äº†ä¸Šæº¢(NaN)æˆ–ä¸‹æº¢(Inf)çš„å¯èƒ½æ€§ã€‚æ›´æ–°è¯¯å·®å¯¼æ•°çš„ä¸»è¦æ–¹æ³•æœ‰ä¸¤ç§ï¼š&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;æ¢¯åº¦ç¼©æ”¾ Gradient Scaling&lt;/li&gt;
  &lt;li&gt;æ¢¯åº¦è£å‰ª Gradient Clipping&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;æ¢¯åº¦ç¼©æ”¾æ¶‰åŠå¯¹è¯¯å·®æ¢¯åº¦å‘é‡è¿›è¡Œå½’ä¸€åŒ–ï¼Œä»¥ä½¿å‘é‡èŒƒæ•°å¤§å°ç­‰äºå®šä¹‰çš„å€¼ï¼Œä¾‹å¦‚1.0ã€‚åªè¦å®ƒä»¬è¶…è¿‡é˜ˆå€¼ï¼Œå°±é‡æ–°ç¼©æ”¾å®ƒä»¬ã€‚å¦‚æœæ¸å˜è¶…å‡ºäº†é¢„æœŸèŒƒå›´ï¼Œåˆ™æ¸å˜è£å‰ªä¼šå¼ºåˆ¶å°†æ¸å˜å€¼ï¼ˆé€ä¸ªå…ƒç´ ï¼‰å¼ºåˆ¶ä¸ºç‰¹å®šçš„æœ€å°å€¼æˆ–æœ€å¤§å€¼ã€‚è¿™äº›æ–¹æ³•é€šå¸¸ç®€ç§°ä¸ºæ¢¯åº¦è£å‰ªã€‚&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;å®ƒæ˜¯ä¸€ç§ä»…è§£å†³è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹çš„æ•°å€¼ç¨³å®šæ€§ï¼Œè€Œä¸èƒ½æ”¹è¿›ç½‘ç»œæ€§èƒ½çš„æ–¹æ³•ã€‚&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;implementation-by-torch&quot;&gt;implementation by torch&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;torch.nn.utils.clip_grad_norm(parameters, max_norm=8, norm_type=2)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;è¿™ä¸ªå‡½æ•°æ˜¯æ ¹æ®å‚æ•°çš„èŒƒæ•°æ¥è¡¡é‡çš„&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;parameters: ä¸€ä¸ªåŸºäºå˜é‡çš„è¿­ä»£å™¨ï¼Œä¼šè¿›è¡Œå½’ä¸€åŒ–. an iterable of Variables that will have gradients normalized&lt;/li&gt;
  &lt;li&gt;max_norm: æ¢¯åº¦æœ€å¤§èŒƒæ•° max norm of the gradients&lt;/li&gt;
  &lt;li&gt;norm_type: è§„å®šèŒƒæ•°çš„ç±»å‹ï¼Œé»˜è®¤ä¸ºL2. type of the used p-norm. Can beâ€™infâ€™for infinity norm&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;returns: å‚æ•°çš„æ€»ä½“èŒƒæ•°(ä½œä¸ºå•ä¸ªå‘é‡æ¥çœ‹)&lt;/p&gt;

&lt;h1 id=&quot;reference&quot;&gt;reference&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/weixin_39653948/article/details/105962326&quot;&gt;ã€è°ƒå‚19ã€‘å¦‚ä½•ä½¿ç”¨æ¢¯åº¦è£å‰ªï¼ˆGradient Clippingï¼‰é¿å…æ¢¯åº¦çˆ†ç‚¸&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 07 Apr 2021 19:12:00 +0800</pubDate>
        <link>https://fuhao7i.github.io/2021/04/07/nn7/</link>
        <guid isPermaLink="true">https://fuhao7i.github.io/2021/04/07/nn7/</guid>
        
        <category>Neural NetworkğŸ¦–</category>
        
        
      </item>
    
      <item>
        <title>Daliæ‚è´§é“ºğŸ°18â€”â€”The role of hook in mmdetection</title>
        <description>&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/238130913&quot;&gt;ç›®æ ‡æ£€æµ‹(MMdetection)-HOOKæœºåˆ¶&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 07 Apr 2021 18:02:00 +0800</pubDate>
        <link>https://fuhao7i.github.io/2021/04/07/sundry18/</link>
        <guid isPermaLink="true">https://fuhao7i.github.io/2021/04/07/sundry18/</guid>
        
        <category>Daliæ‚è´§é“ºğŸ°</category>
        
        
      </item>
    
      <item>
        <title>Daliæ‚è´§é“ºğŸ°17â€”â€”torch è®­ç»ƒè¿‡ç¨‹æŸ¥çœ‹æŸä¸€å±‚çš„æ¢¯åº¦</title>
        <description>&lt;p&gt;åœ¨&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;loss.backward()&lt;/code&gt;ä¹‹åæŸ¥çœ‹æŸä¸€å±‚çš„æ¢¯åº¦&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'=== after loss.backward() ==='&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Mon, 05 Apr 2021 23:58:00 +0800</pubDate>
        <link>https://fuhao7i.github.io/2021/04/05/sundry17/</link>
        <guid isPermaLink="true">https://fuhao7i.github.io/2021/04/05/sundry17/</guid>
        
        <category>Daliæ‚è´§é“ºğŸ°</category>
        
        
      </item>
    
      <item>
        <title>Daliæ‚è´§é“ºğŸ°16â€”â€”Summary of drawing neural network tools</title>
        <description>&lt;h1 id=&quot;1-plotneuralnet&quot;&gt;1. &lt;a href=&quot;https://github.com/HarisIqbal88/PlotNeuralNet&quot;&gt;plotNeuralNet&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20210405111744890.png&quot; center=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-bokeh&quot;&gt;2. &lt;a href=&quot;https://bokeh.pydata.org/en/latest/&quot;&gt;Bokeh&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://bokeh.pydata.org/en/latest/docs/user_guide.html#userguide&quot;&gt;Bokehå®˜æ–¹æ–‡æ¡£&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Bokehæ˜¯ä¸€ä¸ªäº¤äº’å¼å¯è§†åŒ–åº“ï¼Œé¢å‘ç°ä»£Webæµè§ˆå™¨è¿›è¡Œæ¼”ç¤ºã€‚ å®ƒçš„ç›®æ ‡æ˜¯æä¾›ä¼˜é›…ï¼Œç®€æ´çš„å¤šåŠŸèƒ½å›¾å½¢æ„é€ ï¼Œå¹¶é€šè¿‡éå¸¸å¤§æˆ–æµæ•°æ®é›†çš„é«˜æ€§èƒ½äº¤äº’æ¥æ‰©å±•æ­¤åŠŸèƒ½ã€‚ Bokehå¯ä»¥å¸®åŠ©ä»»ä½•æƒ³è¦å¿«é€Ÿè½»æ¾åœ°åˆ›å»ºäº¤äº’å¼å›¾è¡¨ï¼Œä»ªè¡¨æ¿å’Œæ•°æ®åº”ç”¨ç¨‹åºçš„äººã€‚&lt;/p&gt;
</description>
        <pubDate>Mon, 05 Apr 2021 19:16:00 +0800</pubDate>
        <link>https://fuhao7i.github.io/2021/04/05/sundry16/</link>
        <guid isPermaLink="true">https://fuhao7i.github.io/2021/04/05/sundry16/</guid>
        
        <category>Daliæ‚è´§é“ºğŸ°</category>
        
        
      </item>
    
      <item>
        <title>Neural NetworkğŸ¦–6â€”â€”How dose the convolutional layer achieve higher or lower dimensionality?</title>
        <description>&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;The convolution kernel not only has height and width but also has depth&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/2021040509574565.png&quot; center=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And it has the same depth as the feature map being convolved. Therefore, each convolution kernel can traverse all the feature maps of the upper level.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20210405100253974.jpeg&quot; center=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;æ¯ä¸€ä¸ªå·ç§¯æ ¸éå†å®Œæ‰€æœ‰çš„ç‰¹å¾å›¾ä¹‹åï¼Œè¿›è¡Œçº¿æ€§ç›¸åŠ ï¼Œå°±å¾—åˆ°äº†æ–°çš„ç‰¹å¾å›¾ã€‚
After each convolution kernel traverses all the feature maps, linear addition is performed to obtain a new feature map.&lt;/p&gt;
</description>
        <pubDate>Mon, 05 Apr 2021 17:53:00 +0800</pubDate>
        <link>https://fuhao7i.github.io/2021/04/05/nn6/</link>
        <guid isPermaLink="true">https://fuhao7i.github.io/2021/04/05/nn6/</guid>
        
        <category>Neural NetworkğŸ¦–</category>
        
        
      </item>
    
      <item>
        <title>Daliæ‚è´§é“ºğŸ°15â€”â€”lossä¸èƒ½æ­£å¸¸ä¸‹é™ or ä¸‹é™åˆ°ä¸€å®šç¨‹åº¦ä¾¿ä¸ä¸‹é™äº†</title>
        <description>&lt;h1 id=&quot;1-åˆ†æå¦‚ä½•è§£å†³ç¥ç»ç½‘ç»œè®­ç»ƒæ—¶lossä¸ä¸‹é™çš„é—®é¢˜&quot;&gt;1. &lt;a href=&quot;https://blog.ailemon.me/2019/02/26/solution-to-loss-doesnt-drop-in-nn-train/&quot;&gt;åˆ†æ:å¦‚ä½•è§£å†³ç¥ç»ç½‘ç»œè®­ç»ƒæ—¶lossä¸ä¸‹é™çš„é—®é¢˜&lt;/a&gt;&lt;/h1&gt;

&lt;h2 id=&quot;1-å­¦ä¹ ç‡æ²¡æœ‰çµé­‚&quot;&gt;1. å­¦ä¹ ç‡æ²¡æœ‰çµé­‚&lt;/h2&gt;

&lt;p&gt;å­¦ä¹ ç‡æ˜¯ä¸ªç¥å¥‡çš„ä¸œè¥¿, ä½ æ˜¯ä¸æ˜¯ä¹Ÿå¯¹learning rateçš„é€‰å–è€Œè‹¦æ¼è¿‡, æ€»æ˜¯æ„Ÿè§‰ä¸€æˆä¸å˜çš„å­¦ä¹ ç‡ç¼ºå°‘çµé­‚:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;å¤ªå°ï¼Ÿ lossé™ä½çš„å¤ªæ…¢ğŸ’¦&lt;/li&gt;
  &lt;li&gt;å¤ªå¤§ï¼Ÿ losså¯èƒ½è¾¾ä¸åˆ°æœ€ä¼˜, è€Œå¯èƒ½åœ¨æœ€ä¼˜å€¼èŒƒå›´éœ‡åŠ¨&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20210403160419334.png&quot; center=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;è§£å†³-torchoptimlr_scheduler-å­¦ä¹ ç‡ä¸‹é™æœºåˆ¶&quot;&gt;è§£å†³: torch.optim.lr_scheduler å­¦ä¹ ç‡ä¸‹é™æœºåˆ¶&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate&quot;&gt;How to adjust learning rate&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-å­¦ä¹ ç‡ä¸º0&quot;&gt;2. å­¦ä¹ ç‡ä¸º0&lt;/h2&gt;

&lt;p&gt;å­¦ä¹ ç‡ä¸º0ï¼Œç½‘ç»œçš„å‚æ•°ä¸å†æ›´æ–°ï¼Œæ•…æŸå¤±ä¹Ÿä¸ä¼šå†ä¸‹é™ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥çœ‹ä¸€ä¸‹æ˜¯ä¸æ˜¯é”™ç”¨äº†å­¦ä¹ ç‡ä¸‹é™æ–¹æ³•å¯¼è‡´å­¦ä¹ ç‡ä¸º0.&lt;/p&gt;

&lt;h2 id=&quot;3-ä¼˜åŒ–å™¨è®¾ç½®&quot;&gt;3. ä¼˜åŒ–å™¨è®¾ç½®&lt;/h2&gt;

&lt;p&gt;çœ‹çœ‹æˆ‘ä»¬çš„æ¨¡å‹å‚æ•°æ˜¯ä¸æ˜¯æ­£å¸¸è½½å…¥åˆ°ä¼˜åŒ–å™¨ä¸­äº†ã€‚ä¹Ÿå°±æ˜¯çœ‹ä¸€ä¸‹ä¼˜åŒ–å™¨çš„è®¾ç½®æœ‰æ²¡æœ‰å‡ºé”™ã€‚&lt;/p&gt;

&lt;h1 id=&quot;å¼•ç”¨&quot;&gt;å¼•ç”¨.&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/fufu_good/article/details/104340036&quot;&gt;ä½¿ç”¨Pytorchå®ç°å­¦ä¹ ç‡è¡°å‡/é™ä½ï¼ˆlearning rate decayï¼‰&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/qyhaill/article/details/103043637&quot;&gt;torch.optim.lr_schedulerï¼šè°ƒæ•´å­¦ä¹ ç‡&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sat, 03 Apr 2021 04:50:00 +0800</pubDate>
        <link>https://fuhao7i.github.io/2021/04/03/sundry15/</link>
        <guid isPermaLink="true">https://fuhao7i.github.io/2021/04/03/sundry15/</guid>
        
        <category>Daliæ‚è´§é“ºğŸ°</category>
        
        
      </item>
    
  </channel>
</rss>
