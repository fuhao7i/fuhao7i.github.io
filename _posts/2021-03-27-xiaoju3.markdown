---
layout:     post
title:      "å°èŠçš„è¯­ä¹‰åˆ†å‰²3ğŸŒ¼â€”â€”æ•°æ®é¢„å¤„ç†åŠåƒç´ çº§åˆ†ç±»å®ç°åŸç†"
subtitle:   " \"æ•°æ®æ ‡ç­¾é¢„å¤„ç†, Softmaxè¿›è¡Œåƒç´ çº§åˆ†ç±»åŸç†\""
date:       2021-03-27 14:00:00
author:     "fuhao7i"
header-img: "img/in-post/xiaoju.jpg"
catalog: true
tags:
    - å°èŠçš„è¯­ä¹‰åˆ†å‰²ğŸŒ¼
---

# 1. æ•°æ®é¢„å¤„ç†

`æ€è·¯:` è¯»å–train.txtæ–‡ä»¶ï¼Œè·å–è®­ç»ƒå›¾åƒåŠå¯¹åº”æ ‡ç­¾çš„æ–‡ä»¶è·¯å¾„ï¼Œè¯»å–å›¾åƒï¼Œå°†å›¾åƒè½¬åŒ–ä¸º`tensor`ä¹‹åï¼Œ`resize`è°ƒæ•´å›¾åƒå°ºå¯¸å¤§å°å¹¶è¿›è¡Œ`å½’ä¸€åŒ–å¤„ç†`ï¼Œä¹‹åä¹Ÿå¯é€šè¿‡æ—‹è½¬ï¼Œè‰²åï¼Œå¢åŠ å™ªå£°ç­‰æ–¹å¼è¿›è¡Œ`æ•°æ®å¢å¼º`ã€‚æ³¨æ„è¦ä¿è¯å›¾åƒå’Œæ ‡ç­¾çš„å¤„ç†ä¸€è‡´ã€‚

<img src='https://img-blog.csdnimg.cn/20210327141350996.png' center>

`paddingå¯ä»¥ä½¿å›¾åƒåœ¨resizeæ—¶ä¸å¤±çœŸ`

# 2. label map æ ‡ç­¾æ˜ å°„

<img src='https://img-blog.csdnimg.cn/20210328145544433.png' center>

å¦‚å›¾å°±æ˜¯æˆ‘ä»¬çš„è¯­ä¹‰åˆ†å‰²æ ‡ç­¾å›¾åƒï¼Œç›¸åŒé¢œè‰²(åƒç´ å€¼)çš„åƒç´ ç‚¹ä»£è¡¨çš„æ˜¯åŒä¸€ç±»ç‰©ä½“ã€‚å‡è®¾åƒæˆ‘ä»¬è¿™ä¸ªæ ‡ç­¾å›¾åƒæ‰€å±•ç¤ºçš„é‚£æ ·ï¼Œæˆ‘ä»¬éœ€è¦åˆ†å‰²å‡ºæ¥å›¾ç‰‡ä¸­çš„çŒ«å’Œç‹—ï¼Œé‚£å¯¹æˆ‘ä»¬çš„è¯­ä¹‰åˆ†å‰²ä»»åŠ¡æ¥è¯´å°±æ˜¯æ€»å…±è¦åˆ†3ç±»ï¼š0 èƒŒæ™¯ï¼›1 çŒ«ï¼›2 ç‹—ï¼›å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ª`[Height, Width, N_classes]`æ•°ç»„æ¥è¡¨ç¤ºæ¯ä¸€ä¸ªåƒç´ ç‚¹çš„ç±»åˆ«ï¼›å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

<img src='https://img-blog.csdnimg.cn/20210328145242405.png' center>

`label[0, 0] = [1, 0, 0]` è¯´æ˜[0, 0]ä½ç½®æ˜¯èƒŒæ™¯ï¼Œ`label[1, 1] = [0, 1, 0]`è¯´æ˜[1, 1]è¿™ä¸ªåƒç´ ç‚¹å±äºçŒ«ã€‚æˆ‘ä»¬`Reshape`ä¹‹åå¥½åƒæ›´æ–¹ä¾¿å¤§å®¶ç†è§£:

```python
seg_labels = np.reshape(seg_labels, (-1,NCLASSES))
```

```Bash

 [[1, 0, 0],
  [1, 0, 0],
  [1, 0, 0],
  [1, 0, 0],
  [1, 0, 0],
  [0, 1, 0],
  [0, 0, 1],
  [0, 0, 1],
     ...
           ]
```

è¿™å°±æ˜¯æˆ‘ä»¬æœ€åç”¨æ¥å’Œé¢„æµ‹ç»“æœè®¡ç®—æŸå¤±çš„æ•°æ®å•¦ğŸŒ¼`ç›¸ä¿¡å¤§å®¶å¯¹ä¸ºä»€ä¹ˆè¿™æ ·åšè¿˜æœ‰ç‚¹äº‘é‡Œé›¾é‡Œçš„æ„Ÿè§‰ï¼Œé‚£ä¹ˆæ¥ä¸‹æ¥å°±è®©æˆ‘ä»¬æ­å¼€è¯­ä¹‰åˆ†å‰²çš„ç¥ç§˜é¢çº±å§ğŸŒ¼`

# 3. åƒç´ çº§åˆ†ç±»åŸç†

äº†è§£å®Œlableçš„å…·ä½“æ ¼å¼ä¹‹åï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ç½‘ç»œçš„æœ€åå‡ å±‚è®¾è®¡:

```python
x = Conv2D(n_classes,(1,1), padding='vaild' )(x)
x = Reshape((-1,n_classes))(x)
output = Softmax()(x)
```

è¿™ä¸ªå’Œæˆ‘ä»¬labelçš„å¤„ç†æ˜¯ä¸€è‡´çš„ï¼Œè¾“å‡ºçš„æ˜¯æ¯ä¸€ä¸ªåƒç´ ç‚¹å±äºå“ªä¸€ç±»çš„æ¦‚ç‡ï¼Œå¦‚ä¸‹å›¾ï¼š

<img src='https://img-blog.csdnimg.cn/20210328152456675.png' center>

`tensorè¡¨ç¤º:`
```Bash
       Output              Label
 [[0.4, 0.3, 0.3],      [[1, 0, 0],
  [0.7, 0.2, 0.1],       [1, 0, 0],
  [0.8, 0.2, 0.0],       [1, 0, 0],
  [0.8, 0.1, 0.1],       [1, 0, 0],
        ...                 ...
                 ]
```

å°†æˆ‘ä»¬å¤„ç†ä¹‹åçš„labelå’Œé¢„æµ‹å¾—åˆ°çš„ç»“æœä¼ ç»™æˆ‘ä»¬çš„æŸå¤±å‡½æ•°å°±èƒ½è®¡ç®—å‡ºlossäº†ï¼Œè¿™æ ·æˆ‘ä»¬å°±å®ç°äº†åƒç´ çº§çš„åˆ†ç±»â€”â€”â€”â€”ä¹Ÿå°±æ˜¯`è¯­ä¹‰åˆ†å‰²`äº†ğŸŒ¼

**ä¸‹é¢æ˜¯åŒ…å«äº†æ•°æ®é¢„å¤„ç†ï¼ŒæŸå¤±å®šä¹‰ç­‰æ•´ä¸ªæ¨¡å‹è®­ç»ƒè¿‡ç¨‹çš„train.pyæ–‡ä»¶ï¼Œå¤§å®¶ç¨ä½œä¿®æ”¹å°±å¯ä»¥è®­ç»ƒè‡ªå·±çš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹äº†ğŸŒ¼**

**[Keraså®ç°](https://keras.io/zh/models/model/)**

```python
import numpy as np
from PIL import Image

import keras
from keras import backend as K
from keras.optimizers import Adam
from keras.layers import Lambda
from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping

# æ ‡ç­¾åƒç´ å€¼å¯¹åº”çš„ç‰©ä½“ç±»åˆ«, 0ä¸ºèƒŒæ™¯
CLASSES = {
    '[0 0 0]' : 0, # èƒŒæ™¯
    '[7 7 7]' : 1,
    '[26 26 26]' : 2,
}

NCLASSES = 2
HEIGHT = 576
WIDTH = 576

BATCH_SIZE = 2

# train.txtå’Œval.txtçš„æ–‡ä»¶è·¯å¾„
path_train_txt = ''
path_val_txt = ''

# trainçš„å›¾åƒå’Œæ ‡ç­¾è·¯å¾„
path_Xtrain = ''
path_Xlabel = ''
# valçš„å›¾åƒå’Œæ ‡ç­¾è·¯å¾„
path_Yval = ''
path_Ylabel = ''


# labelsæ˜ å°„
def label_map(labels):
    labelmap = np.zeros((int(HEIGHT),int(WIDTH),NCLASSES))
    for h in range(int(HEIGHT)):
        for w in range(int(WIDTH)):
            if str(labels[h, w]) in CLASSES.keys():
                c = CLASSES[str(labels[h, w])]
            else:
                c = 0
            labelmap[h, w, c] = 1
    return labelmap


def data_generator(mode):
    assert mode in ['train', 'val'], \
        'mode must be ethier \'train\' or \'val\''

    if mode == 'train':
        with open(path_train_txt, 'r') as f:
            lines = f.readlines()
        np.random.shuffle(lines)

        n = len(lines)
        path0 = path_Xtrain
        path1 = path_Xlabel
    else:
        with open(path_val_txt, 'r') as f:
            lines = f.readlines()
        np.random.shuffle(lines)

        n = len(lines)
        path0 = path_Yval
        path1 = path_Ylabel 

    i = 0
    while 1:
        images = []
        labels = []
        for _ in range(BATCH_SIZE):
            if i==0:
                np.random.shuffle(lines)
            name = lines[i].split(';')[0]
            img = Image.open(path0 + '/' + name)
            img = img.resize((HEIGHT,WIDTH))
            img = np.array(img)
            img = img/255
            images.append(img)

            name = (lines[i].split(';')[1]).replace("\n", "")
            img = Image.open(path1 + '/' + name)
            img = img.resize((int(HEIGHT),int(WIDTH)))
            img = np.array(img)
            
            seg_labels = label_map(img)
            seg_labels = np.reshape(seg_labels, (-1,NCLASSES))

            labels.append(seg_labels)
            i = (i+1) % n
        yield (np.array(images),np.array(labels))

# å®šä¹‰æŸå¤±å‡½æ•°
def loss(y_true, y_pred):
    crossloss = K.binary_crossentropy(y_true,y_pred)
    loss = K.sum(crossloss)/HEIGHT/WIDTH

    return loss

if __name__ == "__main__":
    
    # ç”¨äºæœ€åä¿å­˜æ¨¡å‹çš„è·¯å¾„
    log_dir = ''

    # åˆ›å»ºæ¨¡å‹
    model = Net()

    # è·å–è®­ç»ƒæ ·æœ¬å’ŒéªŒè¯æ ·æœ¬çš„æ•°ç›®
    with open(path_train_txt, 'r') as f:
        lines = f.readlines()
    num_train = len(lines)
    with open(path_val_txt, 'r') as f:
        lines = f.readlines()
    num_val = len(lines)


    # è®¾ç½®å­¦ä¹ ç‡ä¸‹é™æ–¹æ³•,val_losséªŒè¯æŸå¤±è¿ç»­5ä¸ªepochä¸ä¸‹é™å°±è®©å­¦ä¹ ç‡å‡åŠ
    reduce_lr = ReduceLROnPlateau(
                            monitor='val_loss', 
                            factor=0.5, 
                            patience=5, 
                            verbose=1
                        )
    # æ˜¯å¦éœ€è¦æ—©åœï¼Œå½“val_lossä¸€ç›´ä¸ä¸‹é™çš„æ—¶å€™æ„å‘³ç€æ¨¡å‹åŸºæœ¬è®­ç»ƒå®Œæ¯•ï¼Œå¯ä»¥åœæ­¢
    early_stopping = EarlyStopping(
                            monitor='val_loss', 
                            min_delta=0, 
                            patience=10, 
                            verbose=1
                        )
    # è®¾ç½®æŸå¤±ï¼Œä¼˜åŒ–å™¨
    model.compile(loss = loss,
            optimizer = Adam(lr=1e-3),
            metrics = ['accuracy'])

    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, BATCH_SIZE))

    # å¼€å§‹è®­ç»ƒ
    model.fit_generator(data_generator('train'),
            steps_per_epoch=max(1, num_train//BATCH_SIZE),
            validation_data=data_generator('val'),
            validation_steps=max(1, num_val//BATCH_SIZE),
            epochs=50,
            initial_epoch=0,
            callbacks=[reduce_lr, early_stopping])

    model.save_weights(log_dir+'Dali.h5')


```

**[PyTorchå®ç°](https://fuhao7i.com/2021/03/12/dalitools2/)**

