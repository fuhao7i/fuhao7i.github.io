---
layout:     post
title:      "å°èŠçš„è¯­ä¹‰åˆ†å‰²3ğŸŒ¼â€”â€”åƒç´ çº§åˆ†ç±»å®ç°åŸç†åŠæ•°æ®é¢„å¤„ç†"
subtitle:   " \"æ•°æ®æ ‡ç­¾é¢„å¤„ç†, Softmaxè¿›è¡Œåƒç´ çº§åˆ†ç±»åŸç†\""
date:       2021-03-27 14:00:00
author:     "fuhao7i"
header-img: "img/in-post/xiaoju.jpg"
catalog: true
tags:
    - å°èŠçš„è¯­ä¹‰åˆ†å‰²ğŸŒ¼
---

> é€šè¿‡å°èŠçš„è¯­ä¹‰åˆ†å‰²1ğŸŒ¼ï¼Œæˆ‘ä»¬å·²ç»çŸ¥é“äº†è¯­ä¹‰åˆ†å‰²å…¶å®å°±æ˜¯åƒç´ çº§çš„åˆ†ç±»ä»»åŠ¡ï¼Œä¹Ÿå°±æ˜¯è¯´å®ƒè¦åšçš„æ˜¯ç»™æ¯ä¸€ä¸ªåƒç´ ç‚¹è¿›è¡Œåˆ†ç±»ï¼Œé‚£æˆ‘ä»¬å…·ä½“åº”è¯¥æ€æ ·å®ç°è¿™ä¸ªç‰¹æ®Šçš„åˆ†ç±»ä»»åŠ¡å‘¢ï¼Ÿâ€”â€”â€”â€”ä¸æ€¥ï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹ä¸€ä¸‹æ™®é€šçš„å›¾åƒåˆ†ç±»ä»»åŠ¡æ˜¯æ€æ ·å®ç°çš„

# 0. å›¾åƒåˆ†ç±»ä»»åŠ¡å®ç°åŸç†

å…¶å®æˆ‘ä»¬çš„è¯­ä¹‰åˆ†å‰²â€”â€”åƒç´ çº§åˆ†ç±»å’Œæˆ‘ä»¬çš„æ™®é€šå›¾åƒåˆ†ç±»ä»»åŠ¡è¿˜æ˜¯éå¸¸ç›¸ä¼¼çš„ï¼Œåªä¸è¿‡æ˜¯ä¸€ä¸ªç»™åƒç´ ç‚¹è¿›è¡Œåˆ†ç±»ï¼Œä¸€ä¸ªç»™æ•´ä¸ªå›¾åƒè¿›è¡Œåˆ†ç±»ï¼Œå®ƒä»¬çš„æ ‡ç­¾å¤„ç†æ–¹å¼å’Œæœ€åçš„æŸå¤±è®¡ç®—éƒ½æ˜¯éå¸¸ç›¸ä¼¼çš„ã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬å‡è®¾æœ‰è¿™æ ·ä¸€å †å›¾ç‰‡ï¼Œé‡Œé¢æ€»å…±æœ‰3ä¸ªç±»â€”â€”çŒ«ï¼Œç‹—å’Œç‹¼ï¼Œé‚£ä¹ˆæˆ‘ä»¬å®šä¹‰æ ‡ç­¾çš„æ—¶å€™å¯ä»¥å°†çŒ«ä½œä¸ºç¬¬0ç±»ï¼Œç‹—æ˜¯ç¬¬1ç±»ï¼Œç‹¼æ˜¯ç¬¬2ç±»ï¼Œç„¶åç»™å®ƒä»¬è½¬æ¢æˆåˆ†ç±»å¸¸ç”¨çš„one-hotç¼–ç æ ¼å¼ï¼Œå¦‚ä¸‹æ‰€ç¤º:

```Bash
 ç±»åˆ«    æ ‡ç­¾    one-hot  
 çŒ«      0      [1, 0, 0]
 ç‹—      1      [0, 1, 0]
 ç‹¼      2      [0, 0, 1]
```

æˆ‘ä»¬æŠŠæ¯ä¸€å¼ å›¾ç‰‡å’Œå®ƒçš„one-hotç¼–ç æ ¼å¼æ ‡ç­¾å¯¹åº”èµ·æ¥ï¼Œå°±å¯ä»¥ç”¨äºåé¢çš„æŸå¤±å‡½æ•°è®¡ç®—äº†ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬å†çœ‹çœ‹æˆ‘ä»¬çš„åˆ†ç±»ç½‘ç»œçš„è¾“å‡ºæ˜¯æ€æ ·çš„ã€‚åˆ†ç±»ç½‘ç»œçš„è¾“å‡ºæ˜¯ä¸€ä¸ªä¸€ç»´æ•°ç»„[...]ï¼Œå…·ä½“æ•°ç»„é‡Œé¢æœ‰å‡ ä¸ªå…ƒç´ å’Œæˆ‘ä»¬è¦åˆ†çš„ç±»åˆ«æœ‰å…³ï¼Œæˆ‘ä»¬è¿™é‡Œåˆ†3ç±»ï¼Œæ•°ç»„çš„é•¿åº¦å°±ä¸º3â€”â€”â€”â€”[x0, x1, x2]ï¼Œä¹‹åæˆ‘ä»¬`Softmax([x0, x1, x2])`ï¼Œå¾—åˆ°[p0, p1, p2]ï¼Œå…¶ä¸­p0+p1+p2=1ï¼Œp0ä»£è¡¨çš„æ˜¯å›¾åƒä¸ºç¬¬0ç±»çš„æ¦‚ç‡ï¼Œp1ä»£è¡¨çš„æ˜¯å›¾åƒä¸ºç¬¬1ç±»çš„æ¦‚ç‡ï¼Œä»¥æ­¤ç±»æ¨ã€‚æœ€å¤§æ¦‚ç‡å¯¹åº”ç§ç±»å°±æ˜¯åˆ†ç±»ç½‘ç»œé¢„æµ‹çš„å›¾åƒçš„ç§ç±»ã€‚`ä¾‹` æˆ‘ä»¬å°†æ ‡ç­¾ä¸º[0, 1, 0]çš„å›¾åƒè¾“å…¥åˆ°åˆ†ç±»ç½‘ç»œå¾—åˆ°è¾“å‡º[0.1, 0.7, 0.2]ï¼Œå…¶ä¸­æœ€å¤§æ¦‚ç‡0.7å¯¹åº”çš„ç±»åˆ«ä¸º1ï¼Œåˆ™åˆ†ç±»ç½‘ç»œä»»åŠ¡è¯¥å›¾åƒä¸ºç‹—ã€‚

æœ€åæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹åˆ†ç±»ç½‘ç»œæŸå¤±çš„è®¡ç®—ï¼š**äº¤å‰ç†µ**

$$
\large loss = - (\sum\limits_{i=1}^N y\_true_i * ln( y\_pre_i )) \tag {1}
$$

å…¶ä¸­ $0 < y\_pre_i <= 1$ã€‚å› ä¸ºæˆ‘ä»¬çš„y_trueåªæœ‰ä¸€ä¸ªä¸º1ï¼Œå…¶ä½™å…¨ä¸º0ï¼Œå¸¦å…¥å¯å¾—æˆ‘ä»¬çš„æŸå¤±ä¸º **loss = - ln( y_prei )**ï¼Œå¸¦å…¥æˆ‘ä»¬ä¸Šè¾¹çš„ä¾‹å­å°±æ˜¯**loss = -ln(0.7)**,lnå‡½æ•°åœ¨**(0,1]**ä¸ºå¢å‡½æ•°ï¼ŒåŠ ä¸Šè´Ÿå·ä¸ºå‡å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬çš„åˆ†ç±»ç½‘ç»œåªæœ‰æé«˜å›¾åƒåˆ†ç±»æ­£ç¡®çš„æ¦‚ç‡ï¼Œæˆ‘ä»¬çš„lossæ‰ä¼šå‡å°ã€‚

`æŸå¤±ç†è§£:`

```python
import numpy as np
import math
import tensorflow.keras.backend as K

# ç±»åˆ«    æ ‡ç­¾    one-hot  
# çŒ«      0      [1, 0, 0]
# ç‹—      1      [0, 1, 0]
# ç‹¼      2      [0, 0, 1]

labels = ['0', '1', '2']
y_true = ['1', '0']
y_pred = [ [0.2, 0.6, 0.2],
           [0.3, 0.3, 0.4] ]

sk_log_loss = log_loss(y_true, y_pred, labels=labels)

print('sk_log_loss:', sk_log_loss)


def crossentropy(y, x):
    return -(y * np.log(x))

y_true = np.array([[0, 1, 0], [1, 0, 0]])
y_pred = np.array([[0.2, 0.6, 0.2], [0.3, 0.3, 0.4]])


print("Keras:", K.categorical_crossentropy(K.constant(y_true), K.constant(y_pred)))

loss1 = 0.0
loss2 = 0.0
loss1 = np.array(loss1).astype('float32')
loss2 = np.array(loss2).astype('float32')
for i in range(3):
    loss1 += crossentropy(y_true[0][i], y_pred[0][i])
    loss2 += crossentropy(y_true[1][i], y_pred[1][i])  
mean_loss = (loss1 + loss2) / 2
print("ours :", loss1, loss2, mean_loss)
```

```Bash
sk_log_loss: 0.8573992
Keras: tf.Tensor([0.5108256 1.2039728], shape=(2,), dtype=float32)
ours : 0.51082563 1.2039728 0.8573992
```

çœ‹æ‡‚äº†æ™®é€šçš„å›¾åƒåˆ†ç±»ä»»åŠ¡ä¹‹åï¼Œå†çœ‹æˆ‘ä»¬çš„è¯­ä¹‰åˆ†å‰²ï¼Œå…¶å®å°±æ˜¯ç»™æ¯ä¸€ä¸ªåƒç´ ç‚¹å¯¹åº”ä¸€ä¸ªone-hotç¼–ç æ ‡ç­¾ï¼Œä¹‹åæˆ‘ä»¬çš„è¯­ä¹‰åˆ†å‰²ç½‘ç»œçš„è¾“å‡ºå’Œåˆ†ç±»ç½‘ç»œçš„è¾“å‡ºä¹Ÿæ˜¯ä¸€æ ·çš„ï¼Œä¼šè¾“å‡ºæ¯ä¸€ä¸ªåƒç´ ç‚¹å¯¹åº”æ¯ä¸ªç±»åˆ«çš„æ¦‚ç‡ã€‚å¦‚ä¸‹æ‰€ç¤ºï¼š

```Bash
       Output              Label
 [[0.4, 0.3, 0.3],      [[1, 0, 0],        # ç¬¬1ä¸ªåƒç´ ç‚¹
  [0.7, 0.2, 0.1],       [1, 0, 0],        # ç¬¬2ä¸ªåƒç´ ç‚¹
  [0.8, 0.2, 0.0],       [1, 0, 0],        # ç¬¬ä¸‰ä¸ªåƒç´ ç‚¹
  [0.8, 0.1, 0.1],       [1, 0, 0],        # ç¬¬å››ä¸ªåƒç´ ç‚¹
        ...                 ...
                 ]
```

æ¥ä¸‹æ¥å°±è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹å®ƒåœ¨è¯­ä¹‰åˆ†å‰²ä¸­æ˜¯æ€æ ·å…·ä½“å®ç°çš„å§

# 1. æ•°æ®é¢„å¤„ç†

`æ€è·¯:` è¯»å–train.txtæ–‡ä»¶ï¼Œè·å–è®­ç»ƒå›¾åƒåŠå¯¹åº”æ ‡ç­¾çš„æ–‡ä»¶è·¯å¾„ï¼Œè¯»å–å›¾åƒï¼Œå°†å›¾åƒè½¬åŒ–ä¸º`tensor`ä¹‹åï¼Œ`resize`è°ƒæ•´å›¾åƒå°ºå¯¸å¤§å°å¹¶è¿›è¡Œ`å½’ä¸€åŒ–å¤„ç†`ï¼Œä¹‹åä¹Ÿå¯é€šè¿‡æ—‹è½¬ï¼Œè‰²åï¼Œå¢åŠ å™ªå£°ç­‰æ–¹å¼è¿›è¡Œ`æ•°æ®å¢å¼º`ã€‚æ³¨æ„è¦ä¿è¯å›¾åƒå’Œæ ‡ç­¾çš„å¤„ç†ä¸€è‡´ã€‚

<img src='https://img-blog.csdnimg.cn/20210327141350996.png' center>

`paddingå¯ä»¥ä½¿å›¾åƒåœ¨resizeæ—¶ä¸å¤±çœŸ`

# 2. label map æ ‡ç­¾æ˜ å°„

<img src='https://img-blog.csdnimg.cn/20210328145544433.png' center>

å¦‚å›¾å°±æ˜¯æˆ‘ä»¬çš„è¯­ä¹‰åˆ†å‰²æ ‡ç­¾å›¾åƒï¼Œç›¸åŒé¢œè‰²(åƒç´ å€¼)çš„åƒç´ ç‚¹ä»£è¡¨çš„æ˜¯åŒä¸€ç±»ç‰©ä½“ã€‚å‡è®¾åƒæˆ‘ä»¬è¿™ä¸ªæ ‡ç­¾å›¾åƒæ‰€å±•ç¤ºçš„é‚£æ ·ï¼Œæˆ‘ä»¬éœ€è¦åˆ†å‰²å‡ºæ¥å›¾ç‰‡ä¸­çš„çŒ«å’Œç‹—ï¼Œé‚£å¯¹æˆ‘ä»¬çš„è¯­ä¹‰åˆ†å‰²ä»»åŠ¡æ¥è¯´å°±æ˜¯æ€»å…±è¦åˆ†3ç±»ï¼š0 èƒŒæ™¯ï¼›1 çŒ«ï¼›2 ç‹—ï¼›å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ª`[Height, Width, N_classes]`æ•°ç»„æ¥è¡¨ç¤ºæ¯ä¸€ä¸ªåƒç´ ç‚¹çš„ç±»åˆ«ï¼›å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

<img src='https://img-blog.csdnimg.cn/20210328145242405.png' center>

`label[0, 0] = [1, 0, 0]` è¯´æ˜[0, 0]ä½ç½®æ˜¯èƒŒæ™¯ï¼Œ`label[1, 1] = [0, 1, 0]`è¯´æ˜[1, 1]è¿™ä¸ªåƒç´ ç‚¹å±äºçŒ«ã€‚æˆ‘ä»¬`Reshape`ä¹‹åå¥½åƒæ›´æ–¹ä¾¿å¤§å®¶ç†è§£:

```python
seg_labels = np.reshape(seg_labels, (-1,NCLASSES))
```
**one-hot ç¼–ç **
```Bash

 [[1, 0, 0],
  [1, 0, 0],
  [1, 0, 0],
  [1, 0, 0],
  [1, 0, 0],
  [0, 1, 0],
  [0, 0, 1],
  [0, 0, 1],
     ...
           ]
```

è¿™å°±æ˜¯æˆ‘ä»¬æœ€åç”¨æ¥å’Œé¢„æµ‹ç»“æœè®¡ç®—æŸå¤±çš„æ•°æ®å•¦ğŸŒ¼`ç›¸ä¿¡å¤§å®¶å¯¹ä¸ºä»€ä¹ˆè¿™æ ·åšè¿˜æœ‰ç‚¹äº‘é‡Œé›¾é‡Œçš„æ„Ÿè§‰ï¼Œé‚£ä¹ˆæ¥ä¸‹æ¥å°±è®©æˆ‘ä»¬æ­å¼€è¯­ä¹‰åˆ†å‰²çš„ç¥ç§˜é¢çº±å§ğŸŒ¼`

# 3. åƒç´ çº§åˆ†ç±»åŸç†

äº†è§£å®Œlableçš„å…·ä½“æ ¼å¼ä¹‹åï¼Œæˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ç½‘ç»œçš„æœ€åå‡ å±‚è®¾è®¡:

```python
x = Conv2D(n_classes,(1,1), padding='vaild' )(x)
x = Reshape((-1,n_classes))(x)
output = Softmax()(x)
```

è¿™ä¸ªå’Œæˆ‘ä»¬labelçš„å¤„ç†æ˜¯ä¸€è‡´çš„ï¼Œè¾“å‡ºçš„æ˜¯æ¯ä¸€ä¸ªåƒç´ ç‚¹å±äºå“ªä¸€ç±»çš„æ¦‚ç‡ï¼Œå¦‚ä¸‹å›¾ï¼š

<img src='https://img-blog.csdnimg.cn/20210328152456675.png' center>

`tensorè¡¨ç¤º:`
```Bash
       Output              Label
 [[0.4, 0.3, 0.3],      [[1, 0, 0],
  [0.7, 0.2, 0.1],       [1, 0, 0],
  [0.8, 0.2, 0.0],       [1, 0, 0],
  [0.8, 0.1, 0.1],       [1, 0, 0],
        ...                 ...
                 ]
```

å°†æˆ‘ä»¬å¤„ç†ä¹‹åçš„labelå’Œé¢„æµ‹å¾—åˆ°çš„ç»“æœä¼ ç»™æˆ‘ä»¬çš„æŸå¤±å‡½æ•°å°±èƒ½è®¡ç®—å‡ºlossäº†ï¼Œè¿™æ ·æˆ‘ä»¬å°±å®ç°äº†åƒç´ çº§çš„åˆ†ç±»â€”â€”â€”â€”ä¹Ÿå°±æ˜¯`è¯­ä¹‰åˆ†å‰²`äº†ğŸŒ¼

### å¸®åŠ©ç†è§£æ ‡ç­¾çš„å¤„ç†

```python
import numpy as np
import tensorflow as tf
from PIL import Image
from keras.utils import to_categorical
CLASSES = {
     # é»˜è®¤èƒŒæ™¯ä¸º0
     76 : 1, # å»ºç­‘ç‰©
    150 : 2,  # æ¤è¢«
    255 : 3,# é“è·¯
}

NCLASSES = 4
HEIGHT = 2
WIDTH = 2

labels = [[25, 76],
          [150, 255]]

labels = np.array(labels).astype('int')

labelmap = np.zeros((int(HEIGHT), int(WIDTH)))

for k in CLASSES:
    labelmap[(labels == k)] = CLASSES[k]

labelmap = np.reshape(labelmap, (-1, 1))

labelmap = to_categorical(labelmap, NCLASSES)

print(labelmap)
```

**ä¸‹é¢æ˜¯åŒ…å«äº†æ•°æ®é¢„å¤„ç†ï¼ŒæŸå¤±å®šä¹‰ç­‰æ•´ä¸ªæ¨¡å‹è®­ç»ƒè¿‡ç¨‹çš„train.pyæ–‡ä»¶ï¼Œå¤§å®¶ç¨ä½œä¿®æ”¹å°±å¯ä»¥è®­ç»ƒè‡ªå·±çš„è¯­ä¹‰åˆ†å‰²æ¨¡å‹äº†ğŸŒ¼**

**[Keraså®ç°](https://keras.io/zh/models/model/)**

```python
import numpy as np
from PIL import Image

import keras
from keras import backend as K
from keras.optimizers import Adam
from keras.layers import Lambda
from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping

# æ ‡ç­¾åƒç´ å€¼å¯¹åº”çš„ç‰©ä½“ç±»åˆ«, 0ä¸ºèƒŒæ™¯
CLASSES = {
    '[0 0 0]' : 0, # èƒŒæ™¯
    '[7 7 7]' : 1,
    '[26 26 26]' : 2,
}

NCLASSES = 2
HEIGHT = 576
WIDTH = 576

BATCH_SIZE = 2

# train.txtå’Œval.txtçš„æ–‡ä»¶è·¯å¾„
path_train_txt = ''
path_val_txt = ''

# trainçš„å›¾åƒå’Œæ ‡ç­¾è·¯å¾„
path_Xtrain = ''
path_Xlabel = ''
# valçš„å›¾åƒå’Œæ ‡ç­¾è·¯å¾„
path_Yval = ''
path_Ylabel = ''


# labelsæ˜ å°„
def label_map(labels):
    labelmap = np.zeros((int(HEIGHT),int(WIDTH),NCLASSES))
    for h in range(int(HEIGHT)):
        for w in range(int(WIDTH)):
            if str(labels[h, w]) in CLASSES.keys():
                c = CLASSES[str(labels[h, w])]
            else:
                c = 0
            labelmap[h, w, c] = 1
    return labelmap


def data_generator(mode):
    assert mode in ['train', 'val'], \
        'mode must be ethier \'train\' or \'val\''

    if mode == 'train':
        with open(path_train_txt, 'r') as f:
            lines = f.readlines()
        np.random.shuffle(lines)

        n = len(lines)
        path0 = path_Xtrain
        path1 = path_Xlabel
    else:
        with open(path_val_txt, 'r') as f:
            lines = f.readlines()
        np.random.shuffle(lines)

        n = len(lines)
        path0 = path_Yval
        path1 = path_Ylabel 

    i = 0
    while 1:
        images = []
        labels = []
        for _ in range(BATCH_SIZE):
            if i==0:
                np.random.shuffle(lines)
            name = lines[i].split(';')[0]
            img = Image.open(path0 + '/' + name)
            img = img.resize((HEIGHT,WIDTH))
            img = np.array(img)
            img = img/255
            images.append(img)

            name = (lines[i].split(';')[1]).replace("\n", "")
            img = Image.open(path1 + '/' + name)
            img = img.resize((int(HEIGHT),int(WIDTH)))
            img = np.array(img)
            
            seg_labels = label_map(img)
            seg_labels = np.reshape(seg_labels, (-1,NCLASSES))

            labels.append(seg_labels)
            i = (i+1) % n
        yield (np.array(images),np.array(labels))

# å®šä¹‰æŸå¤±å‡½æ•°
def loss(y_true, y_pred):
    crossloss = K.binary_crossentropy(y_true,y_pred)
    loss = K.sum(crossloss)/HEIGHT/WIDTH

    return loss

if __name__ == "__main__":
    
    # ç”¨äºæœ€åä¿å­˜æ¨¡å‹çš„è·¯å¾„
    log_dir = ''

    # åˆ›å»ºæ¨¡å‹
    model = Net()

    # è·å–è®­ç»ƒæ ·æœ¬å’ŒéªŒè¯æ ·æœ¬çš„æ•°ç›®
    with open(path_train_txt, 'r') as f:
        lines = f.readlines()
    num_train = len(lines)
    with open(path_val_txt, 'r') as f:
        lines = f.readlines()
    num_val = len(lines)


    # è®¾ç½®å­¦ä¹ ç‡ä¸‹é™æ–¹æ³•,val_losséªŒè¯æŸå¤±è¿ç»­5ä¸ªepochä¸ä¸‹é™å°±è®©å­¦ä¹ ç‡å‡åŠ
    reduce_lr = ReduceLROnPlateau(
                            monitor='val_loss', 
                            factor=0.5, 
                            patience=5, 
                            verbose=1
                        )
    # æ˜¯å¦éœ€è¦æ—©åœï¼Œå½“val_lossä¸€ç›´ä¸ä¸‹é™çš„æ—¶å€™æ„å‘³ç€æ¨¡å‹åŸºæœ¬è®­ç»ƒå®Œæ¯•ï¼Œå¯ä»¥åœæ­¢
    early_stopping = EarlyStopping(
                            monitor='val_loss', 
                            min_delta=0, 
                            patience=10, 
                            verbose=1
                        )
    # è®¾ç½®æŸå¤±ï¼Œä¼˜åŒ–å™¨
    model.compile(loss = loss,
            optimizer = Adam(lr=1e-3),
            metrics = ['accuracy'])

    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, BATCH_SIZE))

    # å¼€å§‹è®­ç»ƒ
    model.fit_generator(data_generator('train'),
            steps_per_epoch=max(1, num_train//BATCH_SIZE),
            validation_data=data_generator('val'),
            validation_steps=max(1, num_val//BATCH_SIZE),
            epochs=50,
            initial_epoch=0,
            callbacks=[reduce_lr, early_stopping])

    model.save_weights(log_dir+'Dali.h5')


```

**`ä¸Šé¢çš„æ ‡ç­¾å¤„ç†æ–¹ä¾¿ç†è§£ï¼Œä½†æ˜¯æ—¶é—´å¤æ‚åº¦é«˜ï¼Œåœ¨cupä¸Šå¤„ç†æ…¢ï¼Œä¸‹é¢ä¸ºæ”¹è¿›ç‰ˆæœ¬:`**

```python
import tensorflow as tf
import numpy as np
from PIL import Image
# import keras
from tensorflow import keras
from tensorflow.keras import backend as K
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Lambda
from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.utils import to_categorical
from models.decoders.segnet import resnet50_segnet
import glob

# logging æ¨¡å—, ä¿å­˜æ—¥å¿—æ–‡ä»¶
# ===================>
import logging
logging.basicConfig(filename='./work_dirs/segnet/segnet.log', filemode='a', level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.handlers.clear()
logger.setLevel(level = logging.DEBUG)

formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

console = logging.StreamHandler()
console.setLevel(logging.INFO)
console.setFormatter(formatter)

logger.addHandler(console)
# <==================

# æ ‡ç­¾åƒç´ å€¼å¯¹åº”çš„ç‰©ä½“ç±»åˆ«, 0ä¸ºèƒŒæ™¯
CLASSES = {
    # é»˜è®¤èƒŒæ™¯ä¸º0
     76 : 1,  # å»ºç­‘ç‰©
    150 : 2,  # æ¤è¢«
    255 : 3,  # é“è·¯
}

NCLASSES = 4
HEIGHT = 512
WIDTH = 512

BATCH_SIZE = 8

# train.txtå’Œval.txtçš„æ–‡ä»¶è·¯å¾„
path_train_txt = './dataset/train.txt'
path_val_txt = './dataset/val.txt'

# trainçš„å›¾åƒå’Œæ ‡ç­¾è·¯å¾„
path_Xtrain = './dataset/jpg/'
path_Xlabel = './dataset/png/'
# valçš„å›¾åƒå’Œæ ‡ç­¾è·¯å¾„
path_Yval = './dataset/val_jpg/'
path_Ylabel = './dataset/val_png/'


# labelsæ˜ å°„
def label_map(labels):
    labelmap = np.zeros((int(HEIGHT),int(WIDTH),NCLASSES)).astype('float32')
    for h in range(int(HEIGHT)):
        for w in range(int(WIDTH)):
            if str(labels[h, w]) in CLASSES.keys():
                c = CLASSES[str(labels[h, w])]
            else:
                c = 0
            labelmap[h, w, c] = 1

    return labelmap


def data_generator(mode):
    assert mode in ['train', 'val'], \
        'mode must be ethier \'train\' or \'val\''

    if mode == 'train':
        with open(path_train_txt, 'r') as f:
            lines = f.readlines()
        np.random.shuffle(lines)

        n = len(lines)
        path0 = path_Xtrain
        path1 = path_Xlabel
    else:
        with open(path_val_txt, 'r') as f:
            lines = f.readlines()
        np.random.shuffle(lines)

        n = len(lines)
        path0 = path_Yval
        path1 = path_Ylabel 

    i = 0
    while 1:
        images = []
        labels = []
        for _ in range(BATCH_SIZE):
            if i==0:
                np.random.shuffle(lines)
            name = lines[i].split(';')[0]
            img = Image.open(path0 + name)
            img = img.resize((HEIGHT,WIDTH))
            img = np.array(img).astype('float32')
            img = img/255
            images.append(img)

            name = (lines[i].split(';')[1]).replace("\n", "")
            img = Image.open(path1 + name).convert('L')
            img = img.resize((int(HEIGHT),int(WIDTH)))
            img = np.array(img)
            img = tf.convert_to_tensor(img)

            seg_labels = np.zeros((HEIGHT, WIDTH))
            for k in CLASSES:
                seg_labels[(img == k)] = CLASSES[k]
            seg_labels = np.reshape(seg_labels, (-1,1))
            seg_labels = to_categorical(seg_labels, NCLASSES)
            # print(seg_labels)
            labels.append(seg_labels)
            i = (i+1) % n
        yield (np.array(images).astype('float32'),np.array(labels).astype('float32'))

# å®šä¹‰æŸå¤±å‡½æ•°
def loss(y_true, y_pred):
    crossloss = K.binary_crossentropy(y_true, y_pred)
    loss = K.sum(crossloss)/HEIGHT/WIDTH

    return loss

if __name__ == "__main__":
    
    # ç”¨äºæœ€åä¿å­˜æ¨¡å‹çš„è·¯å¾„
    log_dir = './work_dirs/segnet/'

    # åˆ›å»ºæ¨¡å‹
    model = resnet50_segnet(n_classes=NCLASSES, input_height=HEIGHT, input_width=WIDTH)

    # è·å–è®­ç»ƒæ ·æœ¬å’ŒéªŒè¯æ ·æœ¬çš„æ•°ç›®
    with open(path_train_txt, 'r') as f:
        lines = f.readlines()
    num_train = len(lines)
    with open(path_val_txt, 'r') as f:
        lines = f.readlines()
    num_val = len(lines)


    # è®¾ç½®å­¦ä¹ ç‡ä¸‹é™æ–¹æ³•,val_losséªŒè¯æŸå¤±è¿ç»­5ä¸ªepochä¸ä¸‹é™å°±è®©å­¦ä¹ ç‡å‡åŠ
    reduce_lr = ReduceLROnPlateau(
                            monitor='val_loss', 
                            factor=0.5, 
                            patience=5, 
                            verbose=1
                        )
    # æ˜¯å¦éœ€è¦æ—©åœï¼Œå½“val_lossä¸€ç›´ä¸ä¸‹é™çš„æ—¶å€™æ„å‘³ç€æ¨¡å‹åŸºæœ¬è®­ç»ƒå®Œæ¯•ï¼Œå¯ä»¥åœæ­¢
    early_stopping = EarlyStopping(
                            monitor='val_loss', 
                            min_delta=0, 
                            patience=10, 
                            verbose=1
                        )
    # è®¾ç½®æŸå¤±ï¼Œä¼˜åŒ–å™¨
    model.compile(loss = loss,
            optimizer = Adam(lr=1e-3),
            metrics = ['accuracy'])
    logger.info('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, BATCH_SIZE))
    # print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, BATCH_SIZE))

    # å¼€å§‹è®­ç»ƒ
    history = model.fit(data_generator('train'),
              steps_per_epoch=max(1, num_train//BATCH_SIZE),
              validation_data=data_generator('val'),
              validation_steps=max(1, num_val//BATCH_SIZE),
              epochs=50,
              initial_epoch=0,
              callbacks=[reduce_lr, early_stopping])
    logger.info(history)
    model.save_weights(log_dir+'segnet.h5')
```

**[PyTorchå®ç°](https://fuhao7i.com/2021/03/12/dalitools2/)**

```python
import argparse
import copy
import os
import time
import warnings

from PIL import Image
import torch
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import torch.optim as optim
import matplotlib.pyplot as plt

import torch.nn as nn

# ===================>
import logging
logging.basicConfig(filename='./work_dirs/segnet/segnet.log', filemode='a', level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
logger.setLevel(level = logging.DEBUG)

formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

console = logging.StreamHandler()
console.setLevel(logging.INFO)
console.setFormatter(formatter)

logger.addHandler(console)
# <==================

# æ ‡ç­¾åƒç´ å€¼å¯¹åº”çš„ç‰©ä½“ç±»åˆ«, 0ä¸ºèƒŒæ™¯
CLASSES = {
    '[0 0 0]' : 0,    # èƒŒæ™¯
    '[22 0 255]' : 1, # å»ºç­‘ç‰©
    '[0 255 0]' : 2,  # æ¤è¢«
    '[255 255 255]':3,# é“è·¯
}

NCLASSES = 4
HEIGHT = 512
WIDTH = 512

BATCH_SIZE = 8

# train.txtå’Œval.txtçš„æ–‡ä»¶è·¯å¾„
path_train_txt = './dataset/train.txt'
path_val_txt = './dataset/val.txt'

# trainçš„å›¾åƒå’Œæ ‡ç­¾è·¯å¾„
path_Xtrain = './dataset/jpg/'
path_Xlabel = './dataset/png/'
# valçš„å›¾åƒå’Œæ ‡ç­¾è·¯å¾„
path_Yval = './dataset/val_jpg/'
path_Ylabel = './dataset/val_png/'



# labelsæ˜ å°„
def label_map(labels):
    labelmap = np.zeros((int(HEIGHT),int(WIDTH),NCLASSES))
    for h in range(int(HEIGHT)):
        for w in range(int(WIDTH)):
            if str(labels[h, w]) in CLASSES.keys():
                c = CLASSES[str(labels[h, w])]
            else:
                c = 0
            labelmap[h, w, c] = 1
    return labelmap

class MyDataset(Dataset):  # åˆ›å»ºç±»ï¼šMyDataset,ç»§æ‰¿torch.utils.data.Dataset
    def __init__(self, datatxt, mode, transform=None):
        super(MyDataset, self).__init__()
        fh = open(datatxt, 'r')  # æ‰“å¼€txtï¼Œè¯»å–å†…å®¹
        data = []
        for line in fh:  # æŒ‰è¡Œå¾ªç¯txtæ–‡æœ¬ä¸­çš„å†…å®¹
            words = line.split(';')  # é€šè¿‡æŒ‡å®šåˆ†éš”ç¬¦å¯¹å­—ç¬¦ä¸²è¿›è¡Œåˆ‡ç‰‡
            data.append((words[0], words[1]))  # æŠŠtxté‡Œçš„å†…å®¹è¯»å…¥dataåˆ—è¡¨ä¿å­˜ï¼Œwords[0]æ˜¯å›¾ç‰‡ä¿¡æ¯ï¼Œwords[1]æ˜¯label
        if mode == 'train':
            self.path_train = path_Xtrain
            self.path_label = path_Xlabel
        self.data = data
        self.transform = transform

    def __getitem__(self, index):  # æŒ‰ç…§ç´¢å¼•è¯»å–æ¯ä¸ªå…ƒç´ çš„å…·ä½“å†…å®¹
        fn, label = self.data[index]  # fnæ˜¯å›¾ç‰‡path

        img = Image.open(self.path_train + fn).convert('RGB')

        label = Image.open(self.path_label + fn).convert('RGB')



        # from PIL import Image

        if self.transform is not None:  # æ˜¯å¦è¿›è¡Œtransform
            img = self.transform(img)
        return img, label  # returnå›å“ªäº›å†…å®¹ï¼Œåœ¨è®­ç»ƒæ—¶å¾ªç¯è¯»å–æ¯ä¸ªbatchï¼Œå°±èƒ½è·å¾—å“ªäº›å†…å®¹

    def __len__(self):  # å®ƒè¿”å›çš„æ˜¯æ•°æ®é›†çš„é•¿åº¦ï¼Œå¿…é¡»æœ‰
        return len(self.data)


def main():


    
    # å®ä¾‹åŒ–ç½‘ç»œ
    model = Net()
    # print(model)
    
    if torch.cuda.is_available():
        model =  model.cuda()

    train_transforms = transforms.Compose([
     
        transforms.Resize((512, 512)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5)),
        ])
    
    val_transforms = transforms.Compose([
        transforms.Resize((512, 512)),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5)),
    ])

    train_data = MyDataset(datatxt=path_train_txt, transform=train_transforms)
    train_loader = DataLoader(dataset=train_data, batch_size=2, shuffle=True)

    val_data = MyDataset(datatxt=path_val_txt, transform=val_transforms)
    val_loader = DataLoader(dataset=val_data, batch_size=2, shuffle=True)

    optimizer = optim.SGD(model.module.backbone.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)

    # print('backbone parameters:', model.module.backbone)
    num_epoches = 20
    image = {}
    criterion = nn.CrossEntropyLoss()

    val_acc_history = []
    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    # pretrained_dict = torch.load('/content/drive/MyDrive/search/mmdetection/data/resneXt_imagenet.pth')
    # model_dict = model.state_dict()
    # pretrained_dict = {k: v for k, v in pretrained_dict.items() if 'classifier' not in k}
    # for k in pretrained_dict:
    #     print(k)
    # model_dict.update(pretrained_dict)
    # model.load_state_dict(model_dict)

    for epoch in range(num_epoches):
        print('Epoch {}/{}'.format(epoch + 1, num_epoches))
        print('-' * 10)

        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # Set model to training mode

                running_loss = 0.0
                running_corrects = 0

                for i, (imgs, labels) in enumerate(train_loader):
                    imgs = imgs.cuda(cfg.gpu_ids[0])
                    labels = labels.cuda(cfg.gpu_ids[0])
                    
                    # print(labels)
                    optimizer.zero_grad()       

                    image['img'] = imgs
                    image['img_metas'] = imgs

                    outputs = model.extract_backbone(image, optimizer)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    optimizer.step()
                    
                    _, preds = torch.max(outputs, 1)

                    print('loss:', loss.item())
                    running_loss += loss.item() * imgs.size(0)
                    running_corrects += torch.sum(preds == labels.data)
                    # print('{}/{}'.format(i * 50, len(train_loader.dataset)))

                epoch_loss = running_loss / len(train_loader.dataset)
                epoch_acc = running_corrects.double() / len(train_loader.dataset)

                print(' Loss: {:.4f}, acc: {:.6f} , running_loss: {:6f} , len: {:.6f}'.format(epoch_loss, epoch_acc, running_loss, len(train_loader.dataset)))    


            else:
                optimizer.zero_grad()     
                # if epoch < 10:
                #     break
                model.eval()   # Set model to evaluate mode
                
                running_loss = 0.0
                running_corrects = 0

                for i, (imgs, labels) in enumerate(val_loader):

                    imgs = imgs.cuda(cfg.gpu_ids[0])
                    labels = labels.cuda(cfg.gpu_ids[0])
                    # print(labels)
                    optimizer.zero_grad()

                    image['img'] = imgs
                    image['img_metas'] = imgs
                    
                    outputs = model.extract_backbone(image, optimizer)
                    # print(outputs.shape, labels.shape)
                    loss = criterion(outputs, labels)
                    
                    _, preds = torch.max(outputs, 1)


                    running_loss += loss.item() * imgs.size(0)
                    running_corrects += torch.sum(preds == labels.data)
                # epoch_loss = running_loss / 1000.0
                # epoch_acc = running_corrects.double() / 1000.0
                epoch_loss = running_loss / len(val_loader.dataset)
                epoch_acc = running_corrects.double() / len(val_loader.dataset)

                print(' Val_loss: {:.4f}, Val_acc: {:.6f} '.format(epoch_loss, epoch_acc))
            
                if epoch_acc > best_acc:
                    best_acc = epoch_acc
                    best_model_wts = copy.deepcopy(model.state_dict())
                    torch.save(best_model_wts, '/content/drive/MyDrive/search/mmdetection/data/middle.pth')
                val_acc_history.append(epoch_acc)

            print()

    print('Best val Acc: {:4f}'.format(best_acc))
              
    torch.save(best_model_wts, '/content/drive/MyDrive/search/mmdetection/data/resneXt_imagenet_338x600_best.pth')




if __name__ == '__main__':
    main()

```
