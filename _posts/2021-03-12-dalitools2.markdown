---
layout:     post
title:      "Daliå·¥å…·ç®±ğŸ”§2â€”â€”Torch æ•°æ®é›†å‡†å¤‡ Pipline"
subtitle:   " \"transform to train.txt, Dataset, DataLoader, é¢„å¤„ç†\""
date:       2021-03-12 14:15:00
author:     "fuhao7i"
header-img: "img/in-post/tools.jpg"
catalog: true
tags:
    - Daliå·¥å…·ç®±ğŸ”§
---

# 0. ç”Ÿæˆtrain.txt

> åƒä¸€ä¸ªæ–‡ä»¶å¤¹ä»£è¡¨ä¸€ç±»çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬å¯ä»¥å°†å®ƒçš„æ–‡ä»¶åè¯»å–å‡ºæ¥ï¼ŒæŒ‰ç…§{ æ–‡ä»¶å;ç±»åˆ« }çš„æ ¼å¼å°†å®ƒä»¬ä¿å­˜åˆ°train.txtæ–‡ä»¶ä¸­ä»¥ä¾›æˆ‘ä»¬ä½¿ç”¨ï¼›åŒç†ï¼Œå¯¹äºè¯­ä¹‰åˆ†å‰²æˆ–ç›®æ ‡æ£€æµ‹çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬æŒ‰ç…§ { img;label } çš„æ ¼å¼ä¿å­˜åˆ°train.txtæ–‡ä»¶ä¸­ã€‚

`æ–‡ä»¶ç›®å½•:`

<img src="https://img-blog.csdnimg.cn/20210313143137962.png">

è¿™é‡Œæˆ‘ä»¬å…ˆä»ImageNetæ•°æ®é›†æ¯ä¸ªç±»åˆ«ä¸­éšæœºæŠ½å–30%æ¥ä½œä¸ºè®­ç»ƒé›†ï¼Œå‰©ä¸‹çš„70%ä»¥åå†ç”¨ã€‚

`to_train_txt.py`

```python
import os, random

_label = {'n01924916':0, 'n01943899':1, 'n01950731':2, 'n01968897':3, 'n02317335':4, 'n02319095':5, 'n02321529':6}

train_path = './train/'

pathDir = os.listdir(train_path)

f = open('./train_3.txt', 'w')
ff = open('./train_7.txt', 'w')

for ii in pathDir:
    if ii != '.DS_Store':
        label = str(_label[ii])
        
        rate = 0.3
        filename = os.listdir(train_path + ii)
        filenumber = len(filename)
        picknumber = int(filenumber * rate)

        sample = random.sample(filename, picknumber)

        for ob in filename:
            if ob in sample:
                f.write(ii + '/' + ob + ';' + label + '\n')
            else:
                ff.write(ii + '/' + ob + ';' + label + '\n')


f.close()
ff.close()
```

`éƒ¨åˆ†train_3.txtå±•ç¤º:`

```Bash
...

n02319095/n02319095_350.JPEG;5
n02319095/n02319095_3527.JPEG;5
n02319095/n02319095_10100.JPEG;5
n02319095/n02319095_583.JPEG;5
n02319095/n02319095_1263.JPEG;5
n02319095/n02319095_8412.JPEG;5
n02319095/n02319095_7026.JPEG;5
n02319095/n02319095_2398.JPEG;5
n02319095/n02319095_7030.JPEG;5
n02319095/n02319095_487.JPEG;5
n02319095/n02319095_6733.JPEG;5
n02319095/n02319095_1019.JPEG;5
n02319095/n02319095_8238.JPEG;5
n02319095/n02319095_4077.JPEG;5
n02319095/n02319095_4630.JPEG;5
n02319095/n02319095_444.JPEG;5
n02319095/n02319095_1936.JPEG;5
n02319095/n02319095_2025.JPEG;5
n02319095/n02319095_956.JPEG;5
n02319095/n02319095_3272.JPEG;5

...
```

## random.sample()å‡½æ•°ç”¨æ³•

ç”¨äºéšæœºæˆªå–æŒ‡å®šé•¿åº¦çš„åˆ—è¡¨ï¼Œä¸ä¼šæ”¹å˜åŸåˆ—è¡¨ï¼›

```python
list = [0,1,2,3,4]
rs = random.sample(list, 2)
print(rs)
print(list)

# [2, 4] 
# [0, 1, 2, 3, 4]        
```
**PyTorchè¾“å…¥æ•°æ®Piplineï¼š**

1. åˆ›å»ºä¸€ä¸ª`Dataset`å¯¹è±¡;
2. åˆ›å»ºä¸€ä¸ª`DataLoader`å¯¹è±¡;
3. å¾ªç¯è¿™ä¸ª`DataLoader`å¯¹è±¡ï¼Œå°†`img`å’Œ`label`åŠ è½½åˆ°æ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒ;

# 1. åˆ›å»ºDatasetå¯¹è±¡

åˆ›å»ºçš„æ—¶å€™éœ€ç»§æ‰¿`from torch.utils.data.dataset import Dataset`ç±»ã€‚

**Datasetä¸­ä¸»è¦æœ‰3ä¸ªæ–¹æ³•:**

1. __init__: åˆå§‹åŒ–ä¿¡æ¯ï¼ŒåŒ…æ‹¬è®­ç»ƒæ•°æ®å’Œæ ‡ç­¾çš„è·¯å¾„, transformä¿¡æ¯ç­‰;
2. __getitem__: åœ¨è¿™ä¸ªæ–¹æ³•é‡Œæ ¹æ®ä¼ å…¥çš„ä¸‹æ ‡è¿”å›labelå’Œtransformä¹‹åçš„å›¾ç‰‡tensor;
3. __len__: è¿”å›Datasetçš„é•¿åº¦;

```python
from PIL import Image
import torch
import torchvision.transforms as transforms
from torch.utils.data import Dataset


class MyDataset(Dataset):  # åˆ›ç±»ï¼šMyDataset,ç»§æ‰¿torch.utils.data.Dataset
    def __init__(self, datatxt, transform=None):
        super(MyDataset, self).__init__()
        fh = open(datatxt, 'r')  # æ‰“å¼€txtï¼Œè¯»å–å†…å®¹
        data = []
        for line in fh:  # æŒ‰è¡Œå¾ªç¯txtæ–‡æœ¬ä¸­çš„å†…å®¹
            words = line.split(';')  # é€šè¿‡æŒ‡å®šåˆ†éš”ç¬¦å¯¹å­—ç¬¦ä¸²è¿›è¡Œåˆ‡ç‰‡
            data.append((words[0], int(words[1])))  # æŠŠtxté‡Œçš„å†…å®¹è¯»å…¥dataåˆ—è¡¨ä¿å­˜ï¼Œwords[0]æ˜¯å›¾ç‰‡ä¿¡æ¯ï¼Œwords[1]æ˜¯label

        self.data = data
        self.transform = transform

    def __getitem__(self, index):  # æŒ‰ç…§ç´¢å¼•è¯»å–æ¯ä¸ªå…ƒç´ çš„å…·ä½“å†…å®¹
        fn, label = self.data[index]  # fnæ˜¯å›¾ç‰‡path
        img = Image.open(fn).convert('RGB')  # from PIL import Image

        if self.transform is not None:  # æ˜¯å¦è¿›è¡Œtransform
            img = self.transform(img)
        return img, label  # returnå›å“ªäº›å†…å®¹ï¼Œåœ¨è®­ç»ƒæ—¶å¾ªç¯è¯»å–æ¯ä¸ªbatchï¼Œå°±èƒ½è·å¾—å“ªäº›å†…å®¹

    def __len__(self):  # å®ƒè¿”å›çš„æ˜¯æ•°æ®é›†çš„é•¿åº¦ï¼Œå¿…é¡»æœ‰
        return len(self.imgs)


'''æ ‡å‡†åŒ–ã€å›¾ç‰‡å˜æ¢'''
train_transforms = transforms.Compose([
    transforms.RandomCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor()
    ])

train_data = MyDataset(datatxt='train.txt', transform=train_transforms)

train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=64, shuffle=True)

""" è®­ç»ƒæ—¶:"""
for epoch in range(num_epoches):
    for i, (img, label) in enumerate(dataloader):
        ...
```

## transformå„å‚æ•°çš„ä½œç”¨ï¼š

```Bash
1. è£å‰ªâ€”â€”Crop

ä¸­å¿ƒè£å‰ªï¼štransforms.CenterCrop
éšæœºè£å‰ªï¼štransforms.RandomCrop
éšæœºé•¿å®½æ¯”è£å‰ªï¼štransforms.RandomResizedCrop
ä¸Šä¸‹å·¦å³ä¸­å¿ƒè£å‰ªï¼štransforms.FiveCrop
ä¸Šä¸‹å·¦å³ä¸­å¿ƒè£å‰ªåç¿»è½¬ï¼Œtransforms.TenCrop

2. ç¿»è½¬å’Œæ—‹è½¬â€”â€”Flip and Rotation

ä¾æ¦‚ç‡pæ°´å¹³ç¿»è½¬ï¼štransforms.RandomHorizontalFlip(p=0.5)
ä¾æ¦‚ç‡på‚ç›´ç¿»è½¬ï¼štransforms.RandomVerticalFlip(p=0.5)
éšæœºæ—‹è½¬ï¼štransforms.RandomRotation

3. å›¾åƒå˜æ¢

resizeï¼štransforms.Resize
æ ‡å‡†åŒ–ï¼štransforms.Normalize
è½¬ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–è‡³[0-1]ï¼štransforms.ToTensor
å¡«å……ï¼štransforms.Pad
ä¿®æ”¹äº®åº¦ã€å¯¹æ¯”åº¦å’Œé¥±å’Œåº¦ï¼štransforms.ColorJitter
è½¬ç°åº¦å›¾ï¼štransforms.Grayscale
çº¿æ€§å˜æ¢ï¼štransforms.LinearTransformation()
ä»¿å°„å˜æ¢ï¼štransforms.RandomAffine
ä¾æ¦‚ç‡pè½¬ä¸ºç°åº¦å›¾ï¼štransforms.RandomGrayscale
å°†æ•°æ®è½¬æ¢ä¸ºPILImageï¼štransforms.ToPILImage
transforms.Lambdaï¼šApply a user-defined lambda as a transform.

4. å¯¹transformsæ“ä½œï¼Œä½¿æ•°æ®å¢å¼ºæ›´çµæ´»

transforms.RandomChoice(transforms)ï¼Œ ä»ç»™å®šçš„ä¸€ç³»åˆ—transformsä¸­é€‰ä¸€ä¸ªè¿›è¡Œæ“ä½œ
transforms.RandomApply(transforms, p=0.5)ï¼Œç»™ä¸€ä¸ªtransformåŠ ä¸Šæ¦‚ç‡ï¼Œä¾æ¦‚ç‡è¿›è¡Œæ“ä½œ
transforms.RandomOrderï¼Œå°†transformsä¸­çš„æ“ä½œéšæœºæ‰“ä¹±

```

# 2. åˆ›å»ºDataLoaderå¯¹è±¡

`DataLoader: `å°†è‡ªå®šä¹‰çš„Datasetæ ¹æ®batch sizeå¤§å°ã€æ˜¯å¦shuffleç­‰å°è£…æˆä¸€ä¸ªBatch Sizeå¤§å°çš„Tensorï¼Œç”¨äºåé¢çš„è®­ç»ƒã€‚

```python
from torch.utils.data import Dataset, DataLoader

train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)
```

# 3. å¾ªç¯DataLoaderè¿›è¡Œè®­ç»ƒ

```python
for epoch in range(num_epoches):
    for i, (img, label) in enumerate(dataloader):
        ...
```

# #.å¼•ç”¨

1. [PyTorch å­¦ä¹ ç¬”è®°ï¼ˆä¸‰ï¼‰ï¼štransformsçš„äºŒåäºŒä¸ªæ–¹æ³•](https://blog.csdn.net/u011995719/article/details/85107009)
2. [åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ](https://zh.d2l.ai/index.html)
3. [pytorchä¸€æ­¥ä¸€æ­¥åœ¨VGG16ä¸Šè®­ç»ƒè‡ªå·±çš„æ•°æ®é›†](https://blog.csdn.net/hnu_zzt/article/details/85092092?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-10.control&dist_request_id=1328642.24603.16156240016207327&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-10.control)
4. [PyTorch ImageNet åŸºäºé¢„è®­ç»ƒå…­å¤§å¸¸ç”¨å›¾ç‰‡åˆ†ç±»æ¨¡å‹çš„å®æˆ˜](https://www.cnblogs.com/panchuangai/p/12567996.html)