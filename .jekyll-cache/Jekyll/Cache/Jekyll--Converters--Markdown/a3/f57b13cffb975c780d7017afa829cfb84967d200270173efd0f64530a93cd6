I"~Z<font color="eeepink">ä¸ªäººåšå®¢åœ¨è¿™å‘¢ğŸ½[fuhao7i Blog](https://fuhao7i.com)<font color="eeepink">è§†é¢‘è®²è§£åœ¨è¿™æ‰¾</font>ğŸ¤ª[è¢–æ‰‹å¤©ä¸‹7i](https://space.bilibili.com/481802918)

&gt; Hello, æœ€è¿‘å¾ˆå¤šå°ä¼™ä¼´ä»¬çœ‹äº†æˆ‘åœ¨Bç«™çš„è§†é¢‘ä¹‹åæ¥å’Œæˆ‘äº¤æµå…³äºå¦‚ä½•å®ç°è½¦è¾†çš„éæ³•è¶Šçº¿æ£€æµ‹ä»¥åŠè½¦è¾†åœ¨æ–‘é©¬çº¿ä¸ç¤¼è®©è¡Œäººçš„æ£€æµ‹ç­‰ï¼Œä»Šå¤©æˆ‘ä»¥ä¸€ä¸ªå¼€æºçš„é¡¹ç›®ä¸ºåŸºç¡€æ¥å’Œå¤§å®¶ç®€å•åˆ†äº«ä¸€ä¸‹æŠ€æœ¯å®ç°ï¼Œå¸Œæœ›å¯¹åˆšæ¥è§¦è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„å°ä¼™ä¼´ä»¬æœ‰æ‰€å¸®åŠ©ã€‚

# 1. YOLOv3 + Deepsort

é¦–å…ˆï¼Œçœ‹è¿‡æˆ‘æœ¬ä¸“æ ç¬¬ä¸€ä¸ªè§†é¢‘çš„å°ä¼™ä¼´ä»¬åº”è¯¥æ¸…æ¥šï¼Œæ•´ä¸ªçš„é¡¹ç›®æˆ‘ä»¬æ˜¯åŸºäºä¸€ä¸ªç›®æ ‡è¿½è¸ªç®—æ³•æ¥åšçš„ã€‚å› æ­¤ï¼Œåœ¨è¿™é‡Œæˆ‘é‡‡ç”¨æ¯”è¾ƒç»å…¸çš„ [YOLOv3 + Deepsort](https://github.com/fuhao7i/yolov3_deepsort) æ¥è¿›è¡Œç®€å•çš„è®²è§£ã€‚è¿™æ˜¯ä¸€ä¸ªGithubä¸Šçš„å¼€æºé¡¹ç›®ï¼Œç¯å¢ƒé…ç½®ä¹Ÿæ¯”è¾ƒç®€å•ï¼Œåœ¨`README.md`æ–‡ä»¶ä¸­æè¿°çš„å¾ˆæ¸…æ¥šã€‚åˆ†ä¸ºcpuå’Œgpuä¸¤ä¸ªç‰ˆæœ¬ã€‚

# 2. æå–èƒŒæ™¯.py

å› ä¸ºæˆ‘ä»¬å¤„ç†çš„å¯¹è±¡æ˜¯äº¤é€šæ‘„åƒå¤´ä¸‹çš„åœºæ™¯ï¼Œæ•°æ®æ ¼å¼ä¸ºè§†é¢‘æµæˆ–è€…è§†é¢‘ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦æå–è§†é¢‘çš„ç¬¬ä¸€å¸§ä½œä¸ºèƒŒæ™¯æ¥è¿›è¡Œè½¦é“çº¿çš„æ ‡å®šã€‚ä¸æ¨èä½¿ç”¨æˆªå±çš„æ–¹å¼ï¼Œå› ä¸ºè¿™ä¼šä½¿å›¾åƒçš„å°ºå¯¸å‘ç”Ÿæ”¹å˜ã€‚

```python
import cv2

# è¿™é‡Œæˆ‘ä»¬å–è§†é¢‘çš„ç¬¬ä¸€å¸§æ¥è¿›è¡Œæ ‡æ³¨ã€‚æ³¨æ„âš ï¸ä¸è¦ä½¿ç”¨æˆªå›¾ï¼Œå› ä¸ºæˆªå›¾ä¼šä½¿çš„å›¾åƒå¤§å°ä¸ä¸€è‡´ã€‚
vidcap = cv2.VideoCapture('/Users/apple/Documents/äºŒå¶/ç›®æ ‡è¿½è¸ª/yolov3_deepsort/data/video/1.mp4')
success,image = vidcap.read()
n=1
while n &lt; 30:
	success, image = vidcap.read()
	n+=1
imag = cv2.imwrite('fff.png',image)
if imag ==True:
	print('ok')
```

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/20210120205726886.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Z1aGFvN2k=,size_16,color_FFFFFF,t_70)


# 3. è½¦é“çº¿æ ‡å®š.py

æ ¹æ®æå–çš„`èƒŒæ™¯å›¾ç‰‡`ï¼Œè¿›è¡Œé“è·¯ä¿¡æ¯çš„æ ‡å®šï¼Œå¹¶è¿”å›é“è·¯ä¿¡æ¯çš„ç›¸å…³å‚æ•°ã€‚

```python
import cv2
from PIL import Image
from pylab import *
import csv
import codecs

img = cv2.imread('fff.png')

# cishuæ˜¯éœ€è¦æ ‡è®°çš„å®çº¿çš„ä¸ªæ•°ã€‚è¿™ä¸ªéœ€è¦æ ‡è®°4å¤„å®çº¿ã€‚

cishu = 2
sx = []
bm = []
im = array(Image.open('fff.png'))
ion()
imshow(im)
for cs in range(cishu):

    print('Please click 2 points')
    x = ginput(2)
    print('you clicked:',x)
    sx.append(x)

print('Please click 4 points')
x = ginput(4)
print('you clicked:',x)
bm.append(x)

ioff()
show()
print(im.shape)
jinzhi = []
banmaxian = []
def shixian(x1,y1,x2,y2):
    if x1 == x2:
        k = -999
        b = 0
    else:
        k = (y2-y1)/(x2-x1)
        b = y1 - x1 * k
        # k = int(k)
        # b = int(b)
    return k,b
#data1 = [{'x1':int(x[0][0]),'y1':int(x[0][1]),'x2':int(x[1][0]),'y2':int(x[1][1])}]
# è®¡ç®—å®çº¿çš„å€¼ y = kx + b
for i in sx:
    x = {}
    x1 = int(i[0][0])
    y1 = int(i[0][1])
    x2 = int(i[1][0])
    y2 = int(i[1][1])
    k, b = shixian(x1,y1,x2,y2)
    #cv2.rectangle(img, (x1+15,y1), (x2-15,y2), (0,0,255), -1)
    if y1 &gt; y2:
        yy = y2
        xx = x2
        y2 = y1
        x2 = x1
        y1 = yy
        x1 = xx
    if k != 0:
        for xxx in range(y1,y2):
            xq = (xxx-b)/k
            xq = int(xq)
            cv2.rectangle(img, (xq+15,xxx), (xq-15,xxx), (0,0,255), -1)
    else:
        for xxx in range(x1,x2):
            yq = b
            cv2.rectangle(img, (xxx,yq+15), (xxx,yq-15), (0,0,255), -1)
    x['k'] = k
    x['b'] = b
    print('k:',k,'b:',b)
    jinzhi.append(x)



print(jinzhi)


# data2 = [{'x1':400, 'y1':0,'x2':800,'y2':0,
#           'x3':400, 'y3':800, 'x4':800, 'y4':800}]
# è®¡ç®—æ–‘é©¬çº¿çš„å„é¡¹å€¼ y = kx + b
for i in bm:
    x = {}
    x1 = int(i[0][0])
    y1 = int(i[0][1])
    x2 = int(i[1][0])
    y2 = int(i[1][1])
    y3 = int(i[2][1])
    k, b = shixian(x1,y1,x2,y2)
    c = y3 - y1
    x['k'] = k
    x['b'] = b
    x['c'] = c
    x['x1'] = x1
    x['x2'] = x2

    cv2.rectangle(img, (x1,y1+c), (x2,y2), (0,255,0), 4)
    banmaxian.append(x)

print(banmaxian)
cv2.imwrite('001_new.png', img)

# å°†è·å¾—çš„å®çº¿å’Œæ–‘é©¬çº¿ä¿¡æ¯å†™å…¥ç›¸åº”çš„æ–‡ä»¶ã€‚

with open("shixian.txt", 'w') as f:
    for s in jinzhi:
        f.write(str(s) + '\n')

with open("banmaxian.txt", 'w') as f:
    for s in banmaxian:
        f.write(str(s) + '\n')

```

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/20210120205811935.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Z1aGFvN2k=,size_16,color_FFFFFF,t_70)


# 4. è½¦ç‰Œè¯†åˆ«æ¨¡å—

è¿™é‡Œæˆ‘ä»¬å¯ä»¥è‡ªå·±è®­ç»ƒæ¨¡å‹ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å¼€æºé¡¹ç›®`HyperLPR`ï¼Œæ¥è¿›è¡Œè½¦ç‰Œçš„è¯†åˆ«ã€‚

```python
                # æˆªå–è½¦è¾†å›¾ç‰‡
                cropped = img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]
                # ä¼ å…¥HyperLPRæ¨¡å‹è¯†åˆ«è½¦ç‰Œä¿¡æ¯
                xinxi = HyperLPR_plate_recognition(cropped)
```

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/20210120205825360.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Z1aGFvN2k=,size_16,color_FFFFFF,t_70)


# 4.1 è½¦ç‰Œä¿¡æ¯æ‹©ä¼˜è¿­ä»£

è½¦ç‰Œå·çš„è¯†åˆ«æ˜¯ä»è½¦è¾†å‡ºç°åœ¨ç”»é¢çš„ç¬¬ä¸€å¸§å¼€å§‹ï¼Œä¸€ç›´åˆ°è½¦è¾†æ¶ˆå¤±åœ¨ç”»é¢ä¸­ã€‚æˆ‘ä»¬å¹¶ä¸èƒ½äº‹å…ˆç¡®å®šåœ¨å“ªä¸€å¸§å¯¹è½¦ç‰Œçš„è¯†åˆ«æ•ˆæœæœ€å¥½ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨è½¦è¾†å‡ºç°çš„ç¬¬ä¸€å¸§ï¼Œå°±å°†å®ƒçš„`id`å’Œ`è½¦ç‰Œä¿¡æ¯`ä¼ å…¥å­—å…¸`chepaixinxi`ä¿å­˜èµ·æ¥ã€‚å¦‚æœå½“å‰å¸§æ¯”ä¹‹å‰çš„è¯†åˆ«æ•ˆæœéƒ½å¥½(`ç½®ä¿¡åº¦é«˜`)ï¼Œæˆ‘ä»¬å°±ç”¨å®ƒæ›¿æ¢ä¹‹å‰çš„è½¦ç‰Œä¿¡æ¯ã€‚

å¦ä¸€æ–¹é¢ï¼Œä¸ºäº†èŠ‚çœè®¡ç®—èµ„æºï¼Œåªè¦æ˜¯è¯¥è½¦åœ¨æŸä¸€å¸§çš„è½¦ç‰Œç½®ä¿¡åº¦é«˜äº0.9ï¼Œæˆ‘ä»¬å°±ä¸å†å°†å…¶ä¼ å…¥è½¦ç‰Œè¯†åˆ«æ¨¡å—ã€‚

```python
                # å®ç°è½¦ç‰Œä¿¡æ¯çš„æ‹©ä¼˜è¿­ä»£
                if str(track.track_id) in chepaixinxi:
                    if xinxi:
                        chepai = chepaixinxi[str(track.track_id)]
                        if chepai[1] &lt; xinxi[0][1]:
                            cheche = xinxi[0]
                            chepaixinxi[str(track.track_id)] = cheche
                            img = cv2ImgAddText(img,chepaixinxi[str(track.track_id)][0]+':'+str(round(chepaixinxi[str(track.track_id)][1], 2)),int(bbox[0]) , int(bbox[1]),(0,0,255),20)
                        else:
                            img = cv2ImgAddText(img,chepaixinxi[str(track.track_id)][0]+':'+str(round(chepaixinxi[str(track.track_id)][1], 2)),int(bbox[0]) , int(bbox[1]),(0,0,255),20)
                elif xinxi :
                    cheche = xinxi[0]
                    chepaixinxi[str(track.track_id)] = cheche
                    img = cv2ImgAddText(img,chepaixinxi[str(track.track_id)][0]+':'+str(round(chepaixinxi[str(track.track_id)][1], 2)),int(bbox[0]) , int(bbox[1]),(0,0,255),20)
```

# 5. è½¦è¾†éæ³•è¶Šçº¿æ£€æµ‹

æœ‰äº† `4. è½¦ç‰Œä¿¡æ¯æ‹©ä¼˜è¿­ä»£`ï¼Œæˆ‘ä»¬ä¸éš¾å°†è½¦è¾†åœ¨ä¸Šä¸€å¸§çš„ä½ç½®ä¿å­˜ä¸‹æ¥ã€‚å¦‚æœè½¦è¾†åœ¨ä¸Šä¸€å¸§çš„ä½ç½®å’Œåœ¨è¿™ä¸€å¸§çš„ä½ç½®åˆ†åˆ«ä½äºè½¦é“çº¿å®çº¿çš„ä¸¤ä¾§ï¼Œæˆ–è€…è½åœ¨äº†å®çº¿ä¸Šï¼Œæˆ‘ä»¬å°±åˆ¤å®šè½¦è¾†éæ³•è¶Šå®çº¿äº†ã€‚

`è¿™é‡Œæˆ‘åªå†™å½“å‰å¸§è½åœ¨å®çº¿ä¸Šè¿›è¡Œæ¼”ç¤º`ğŸ˜‚
```python
                # è®¡ç®—è½¦çš„ä¸­å¿ƒç‚¹åæ ‡
                diet1 = (int(bbox[3])-int(bbox[1]))/2
                diet2 = (int(bbox[2])-int(bbox[0]))/2
                x = int(bbox[1]) + diet1
                y = int(bbox[0]) + diet2

                # å¦‚æœè½¦çš„ä¸­å¿ƒç‚¹è½åœ¨å®çº¿çš„â€èŒƒå›´â€œå†…ï¼Œå°±åˆ¤æ–­è½¦è¾†éæ³•è¶Šçº¿ã€‚
                for i in k:
                    i = eval(i)
                    # ä¿®æ”¹
                    if x &gt; i['y1'] and x &lt; i['y2']:
                        if x &gt; y*i['k']+i['b']-15 and x &lt; y*i['k']+i['b']+15:
                            img = cv2ImgAddText(img,'éæ³•è¶Šçº¿',int(bbox[0]) , int(bbox[1]+20),(255,0,0),20)
                            print('carè¿è§„ï¼è¿è§„ç±»å‹ï¼šè¶Šå®çº¿ï¼',xinxi)

```

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/20210120205854221.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Z1aGFvN2k=,size_16,color_FFFFFF,t_70)


# 6. è½¦è¾†æ–‘é©¬çº¿ä¸ç¤¼è®©è¡Œäººæ£€æµ‹

æœ€ç®€å•ç²—æš´çš„åšæ³•ï¼šè¡Œäººåœ¨æ–‘é©¬çº¿ä¸Šæ—¶ï¼Œè½¦è¾†ä¹Ÿåœ¨æ–‘é©¬çº¿ä¸Š ==&gt; è½¦è¾†ä¸ç¤¼è®©è¡Œäººã€‚

```python
        on_bmx = []
        for i in xingren:
            for ix in banma:
                ix = eval(ix)
                if on_banmaxian(ix['k'], ix['b'], ix['c'], ix['x1'], ix['x2'],ix['y1'],ix['y2'],i[0],i[1]):
                    on_bmx.append(i[1])
        on_bmx.sort()

        # è½¦è¾†æ–‘é©¬çº¿ä¸ç¤¼è®©è¡Œäººæ£€æµ‹ï¼Œå¹¶è®°å½•å®ƒçš„è½¦ç‰Œä¿¡æ¯å’Œè¿è§„æƒ…å†µ
        for track in tracker.tracks:
            if not track.is_confirmed() or track.time_since_update &gt; 1:
                continue 
            
            bbox = track.to_tlbr()
            class_name = track.get_class()
            if class_name == 'car':
                diet1 = (int(bbox[3])-int(bbox[1]))/2
                diet2 = (int(bbox[2])-int(bbox[0]))/2
                x = int(bbox[1]) + diet1
                y = int(bbox[0]) + diet2
                for ix in banma:
                    ix = eval(ix)
                    if on_banmaxian(ix['k'],ix['b'],ix['c'],ix['x1'],ix['x2'],ix['y1'],ix['y2'],x,y):
                        if len(on_bmx) != 0:
            
                            if str(track.track_id) in chepaixinxi:
                                img = cv2ImgAddText(img,'ä¸ç¤¼è®©è¡Œäºº',int(bbox[0]) , int(bbox[1]+40),(255,0,0),20)
                                print('carè¿è§„:æ²¡æœ‰ç¤¼è®©è¡Œäºº!',chepaixinxi[str(track.track_id)][0])
                            else:
                                img = cv2ImgAddText(img,'ä¸ç¤¼è®©è¡Œäºº',int(bbox[0]) , int(bbox[1]+40),(255,0,0),20)
                                print('carè¿è§„:æ²¡æœ‰ç¤¼è®©è¡Œäºº!')
```

å…¶å®ï¼Œè¿™æ ·åšï¼Œæœ‰ä¸€ç§æƒ…å†µä¼šè¯¯åˆ¤: `è¡Œäººå‘å‰èµ°ï¼Œèº«åæœ‰è½¦é€šè¿‡ï¼Œè¿™æ ·è½¦è¾†ä¸ç”¨ç¤¼è®©è¡Œäºº`

`è§£å†³æ–¹æ³•ï¼š`æˆ‘ä»¬è¿˜æ˜¯å¯ä»¥æ ¹æ®`4. è½¦ç‰Œä¿¡æ¯æ‹©ä¼˜è¿­ä»£`ï¼Œè®°å½•è¡Œäººä¸Šä¸€å¸§å’Œå½“å‰å¸§çš„ä½ç½®ï¼Œè¿™æ ·ï¼Œé€šè¿‡ä¸¤å¸§ä¹‹é—´ï¼Œè¡Œäººçš„ä½ç½®å˜åŒ–æˆ‘ä»¬ä¾¿å¯ä»¥çŸ¥é“è¡Œäººçš„å‰è¿›æ–¹å‘:`å‘å·¦`, `å‘å³`æˆ– `åŸåœ°ä¸åŠ¨`, è¿™æ ·æˆ‘ä»¬ä¾¿å¯ä»¥å®ç°æ›´åŠ å®Œå–„çš„è½¦è¾†åœ¨æ–‘é©¬çº¿ä¸ç¤¼è®©è¡Œäººçš„åŠŸèƒ½äº†ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/20210120205906348.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Z1aGFvN2k=,size_16,color_FFFFFF,t_70)


# 7. æ€»ç»“

å¸Œæœ›å¯ä»¥å¯¹åˆšå…¥é—¨çš„å°ä¼™ä¼´ä»¬æœ‰æ‰€å¯å‘ï¼Œè¿™åªæ˜¯ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼Œæ›´å¤šçš„æœ‰è¶£çš„åŠŸèƒ½éœ€è¦ä½ è‡ªå·±å–å¼€å‘å“¦å“¦å“¦å“¦å“¦å“¦ï½ï½ï½

`object_tracker.py`
```python
import time, random
import numpy as np
from absl import app, flags, logging
from absl.flags import FLAGS
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
from yolov3_tf2.models import (
    YoloV3, YoloV3Tiny
)
from yolov3_tf2.dataset import transform_images
from yolov3_tf2.utils import draw_outputs, convert_boxes

from deep_sort import preprocessing
from deep_sort import nn_matching
from deep_sort.detection import Detection
from deep_sort.tracker import Tracker
from tools import generate_detections as gdet
from PIL import Image
from hyperlpr import *
from PIL import Image, ImageDraw, ImageFont



flags.DEFINE_string('classes', './data/labels/coco.names', 'path to classes file')
flags.DEFINE_string('weights', './weights/yolov3.tf',
                    'path to weights file')
flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')
flags.DEFINE_integer('size', 416, 'resize images to')
flags.DEFINE_string('video', './data/video/test.mp4',
                'path to video file or number for webcam)')
flags.DEFINE_string('output','./data/video/result_out.avi', 'path to output video')
flags.DEFINE_string('output_format', 'XVID', 'codec used in VideoWriter when saving video to file')
flags.DEFINE_integer('num_classes', 80, 'number of classes in the model')


def cv2ImgAddText(img, text, left, top, textColor=(0, 255, 0), textSize=20):
    if (isinstance(img, np.ndarray)):  # åˆ¤æ–­æ˜¯å¦OpenCVå›¾ç‰‡ç±»å‹
        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img)
    fontStyle = ImageFont.truetype(
        "simsun.ttc", textSize, encoding="utf-8")
    draw.text((left, top), text, textColor, font=fontStyle)
    return cv2.cvtColor(np.asarray(img), cv2.COLOR_RGB2BGR)

# åˆ¤æ–­æ˜¯å¦åœ¨æ–‘é©¬çº¿ä¸Š

def on_banmaxian(k,b,c,x1,x2,y1,y2,x,y):

    if x&gt;y1+c and x &lt; y2 and y &gt; x1 and y &lt; x2:
        return True
    else: return False

def main(_argv):

    # å®çº¿å®šä¹‰
    with open("shixian.txt", 'r') as f:
        k = [line.rstrip('\n') for line in f]
    # æ–‘é©¬çº¿å®šä¹‰
    with open("banmaxian.txt", 'r') as f:
        banma = [line.rstrip('\n') for line in f]

    max_cosine_distance = 0.5
    nn_budget = None
    nms_max_overlap = 1.0
    
    #initialize deep sort
    model_filename = 'model_data/mars-small128.pb'
    encoder = gdet.create_box_encoder(model_filename, batch_size=1)
    metric = nn_matching.NearestNeighborDistanceMetric("cosine", max_cosine_distance, nn_budget)
    tracker = Tracker(metric)

    physical_devices = tf.config.experimental.list_physical_devices('GPU')
    if len(physical_devices) &gt; 0:
        tf.config.experimental.set_memory_growth(physical_devices[0], True)

    if FLAGS.tiny:
        yolo = YoloV3Tiny(classes=FLAGS.num_classes)
    else:
        yolo = YoloV3(classes=FLAGS.num_classes)

    yolo.load_weights(FLAGS.weights)
    logging.info('weights loaded')

    class_names = [c.strip() for c in open(FLAGS.classes).readlines()]
    logging.info('classes loaded')

    try:
        vid = cv2.VideoCapture(int(FLAGS.video))
    except:
        vid = cv2.VideoCapture(FLAGS.video)

    out = None

    if FLAGS.output:
        # by default VideoCapture returns float instead of int
        width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = int(vid.get(cv2.CAP_PROP_FPS))
        codec = cv2.VideoWriter_fourcc(*FLAGS.output_format)
        out = cv2.VideoWriter(FLAGS.output, codec, fps, (width, height))
        list_file = open('detection.txt', 'w')
        frame_index = -1 
    
    fps = 0.0
    count = 0 
    #è½¦ç‰Œä¿¡æ¯å­—å…¸ï¼Œå…¨å±€å˜é‡ï¼Œå®ç°å¯¹è½¦ç‰Œè¯†åˆ«ä¿¡æ¯çš„æ‹©ä¼˜è¿­ä»£
    chepaixinxi = {}
    while True:
        _, img = vid.read()
        # print(img.shape)
        if img is None:
            logging.warning("Empty Frame")
            time.sleep(0.1)
            count+=1
            if count &lt; 3:
                continue
            else: 
                break
        
        img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) 
        img_in = tf.expand_dims(img_in, 0)
        img_in = transform_images(img_in, FLAGS.size)

        t1 = time.time()
        boxes, scores, classes, nums = yolo.predict(img_in,steps = 1)
        classes = classes[0]
        names = []
        for i in range(len(classes)):
            names.append(class_names[int(classes[i])])
        #print(names)
        names = np.array(names)
        #print(names)
        


        converted_boxes = convert_boxes(img, boxes[0])
        features = encoder(img, converted_boxes)
        detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature in zip(converted_boxes, scores[0], names, features)]
        
        #initialize color map
        cmap = plt.get_cmap('tab20b')
        colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]

        # run non-maxima suppresion
        boxs = np.array([d.tlwh for d in detections])
        scores = np.array([d.confidence for d in detections])
        classes = np.array([d.class_name for d in detections])
        indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores)
        detections = [detections[i] for i in indices]        

        # Call the tracker
        tracker.predict()
        tracker.update(detections)
        num = 0
        #print(len(tracker.tracks))

        # ç»Ÿè®¡è½¦å’Œè¡Œäººçš„æ•°é‡
        car_num = 0
        person_num = 0
        
        # è®°å½•è¡Œäººä½ç½®
        xingren = []

        # åœ¨å¸§ä¸Šæ ‡æ³¨è½¦é“çº¿

        for i in banma:
            i = eval(i)
            cv2.rectangle(img, (i['x1'],i['y1']+i['c']), (i['x2'],i['y2']), (0,255,0), 4)#ç”»æ–‘é©¬çº¿
        for i in k:
            i = eval(i)
            if i['k'] != 0:
                for xxx in range(i['y1'],i['y2']):
                    xq = (xxx-i['b'])/i['k']
                    xq = int(xq)
                    cv2.rectangle(img, (xq+5,xxx), (xq-5,xxx), (0,0,255), -1)
            else:
                for xxx in range(i['x1'],i['x2']):
                    yq = i['b']
                    cv2.rectangle(img, (xxx,yq+5), (xxx,yq-5), (0,0,255), -1)


        for track in tracker.tracks:
            if not track.is_confirmed() or track.time_since_update &gt; 1:
                continue 
            
            bbox = track.to_tlbr()
            class_name = track.get_class()

            # ç»Ÿè®¡è½¦è¾†å’Œè¡Œäººæ•°é‡
            if class_name == 'car':
                car_num += 1
            elif class_name == 'person':
                person_num += 1 

            color = colors[int(track.track_id) % len(colors)]
            color = [i * 255 for i in color]
            cv2.rectangle(img, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, 2)

            cv2.rectangle(img, (int(bbox[0]), int(bbox[1]-30)), (int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17, int(bbox[1])), color, -1)
            cv2.putText(img, class_name + "-" + str(track.track_id),(int(bbox[0]) , int(bbox[1]-10)),0, 0.75, (255,255,255),2)
         

            if class_name == 'person':
                # è®¡ç®—å‡ºè¡Œäººçš„ä½ç½®ï¼ˆç”¨è¡Œäººè„šçš„ä½ç½®å®šä¹‰è¡Œäººæ‰€åœ¨ä½ç½®ï¼‰
                per = int((int(bbox[2])+int(bbox[0]))/2)

                xingren.append(((int(bbox[3]),per)))
      

            if class_name == 'car' and (int(bbox[3])-int(bbox[1]))&gt;100 and (int(bbox[2])-int(bbox[0])&gt;200):
                
                # æˆªå–è½¦è¾†å›¾ç‰‡
                cropped = img[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]
                # ä¼ å…¥HyperLPRæ¨¡å‹è¯†åˆ«è½¦ç‰Œä¿¡æ¯
                xinxi = HyperLPR_plate_recognition(cropped)

                # è®¡ç®—è½¦çš„ä¸­å¿ƒç‚¹åæ ‡
                diet1 = (int(bbox[3])-int(bbox[1]))/2
                diet2 = (int(bbox[2])-int(bbox[0]))/2
                x = int(bbox[1]) + diet1
                y = int(bbox[0]) + diet2

                # å¦‚æœè½¦çš„ä¸­å¿ƒç‚¹è½åœ¨å®çº¿çš„â€èŒƒå›´â€œå†…ï¼Œå°±åˆ¤æ–­è½¦è¾†éæ³•è¶Šçº¿ã€‚
                for i in k:
                    i = eval(i)
                    # ä¿®æ”¹
                    if x &gt; i['y1'] and x &lt; i['y2']:
                        if x &gt; y*i['k']+i['b']-15 and x &lt; y*i['k']+i['b']+15:
                            img = cv2ImgAddText(img,'éæ³•è¶Šçº¿',int(bbox[0]) , int(bbox[1]+20),(255,0,0),20)
                            print('carè¿è§„ï¼è¿è§„ç±»å‹ï¼šè¶Šå®çº¿ï¼',xinxi)

                # å®ç°è½¦ç‰Œä¿¡æ¯çš„æ‹©ä¼˜è¿­ä»£
                if str(track.track_id) in chepaixinxi:
                    if xinxi:
                        chepai = chepaixinxi[str(track.track_id)]
                        if chepai[1] &lt; xinxi[0][1]:
                            cheche = xinxi[0]
                            chepaixinxi[str(track.track_id)] = cheche
                            img = cv2ImgAddText(img,chepaixinxi[str(track.track_id)][0]+':'+str(round(chepaixinxi[str(track.track_id)][1], 2)),int(bbox[0]) , int(bbox[1]),(0,0,255),20)
                        else:
                            img = cv2ImgAddText(img,chepaixinxi[str(track.track_id)][0]+':'+str(round(chepaixinxi[str(track.track_id)][1], 2)),int(bbox[0]) , int(bbox[1]),(0,0,255),20)
                elif xinxi :
                    cheche = xinxi[0]
                    chepaixinxi[str(track.track_id)] = cheche
                    img = cv2ImgAddText(img,chepaixinxi[str(track.track_id)][0]+':'+str(round(chepaixinxi[str(track.track_id)][1], 2)),int(bbox[0]) , int(bbox[1]),(0,0,255),20)

        print('car name:',car_num,'person num:',person_num)
                
        
        on_bmx = []
        for i in xingren:
            for ix in banma:
                ix = eval(ix)
                if on_banmaxian(ix['k'], ix['b'], ix['c'], ix['x1'], ix['x2'],ix['y1'],ix['y2'],i[0],i[1]):
                    on_bmx.append(i[1])
        on_bmx.sort()

        # è½¦è¾†æ–‘é©¬çº¿ä¸ç¤¼è®©è¡Œäººæ£€æµ‹ï¼Œå¹¶è®°å½•å®ƒçš„è½¦ç‰Œä¿¡æ¯å’Œè¿è§„æƒ…å†µ
        for track in tracker.tracks:
            if not track.is_confirmed() or track.time_since_update &gt; 1:
                continue 
            
            bbox = track.to_tlbr()
            class_name = track.get_class()
            if class_name == 'car':
                diet1 = (int(bbox[3])-int(bbox[1]))/2
                diet2 = (int(bbox[2])-int(bbox[0]))/2
                x = int(bbox[1]) + diet1
                y = int(bbox[0]) + diet2
                for ix in banma:
                    ix = eval(ix)
                    if on_banmaxian(ix['k'],ix['b'],ix['c'],ix['x1'],ix['x2'],ix['y1'],ix['y2'],x,y):
                        if len(on_bmx) != 0:
            
                            if str(track.track_id) in chepaixinxi:
                                img = cv2ImgAddText(img,'ä¸ç¤¼è®©è¡Œäºº',int(bbox[0]) , int(bbox[1]+40),(255,0,0),20)
                                print('carè¿è§„:æ²¡æœ‰ç¤¼è®©è¡Œäºº!',chepaixinxi[str(track.track_id)][0])
                            else:
                                img = cv2ImgAddText(img,'ä¸ç¤¼è®©è¡Œäºº',int(bbox[0]) , int(bbox[1]+40),(255,0,0),20)
                                print('carè¿è§„:æ²¡æœ‰ç¤¼è®©è¡Œäºº!')
                


        print(chepaixinxi.items())

        fps  = ( fps + (1./(time.time()-t1)) ) / 2
        cv2.putText(img, "FPS: {:.2f}".format(fps)+'  car num:'+str(car_num)+'    '+'person num:'+str(person_num), (0, 30),
                          cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)
        cv2.imshow('output', img)
        if FLAGS.output:
            out.write(img)
            frame_index = frame_index + 1
            list_file.write(str(frame_index)+' ')
            if len(converted_boxes) != 0:
                for i in range(0,len(converted_boxes)):
                    list_file.write(str(converted_boxes[i][0]) + ' '+str(converted_boxes[i][1]) + ' '+str(converted_boxes[i][2]) + ' '+str(converted_boxes[i][3]) + ' ')
            list_file.write('\n')

        if cv2.waitKey(1) == ord('q'):
            break
    vid.release()
    if FLAGS.ouput:
        out.release()
        list_file.close()
    cv2.destroyAllWindows()


if __name__ == '__main__':
    try:
        app.run(main)
    except SystemExit:
        pass
```
</font>
:ET